{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/home/sindjoung/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:44: FutureWarning: read_table is deprecated, use read_csv instead.\n"
    },
    {
     "data": {
      "text/plain": "0.9661016949152542"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 288x216 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 288x216 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "#import MyAnalysis \n",
    "rcParams['figure.figsize'] = 4,3\n",
    "\n",
    "#Import for threading\n",
    "\n",
    "import random\n",
    "import sys\n",
    "from threading import Thread, RLock\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "\n",
    "\n",
    "#Function that computes the median value of RSSI given a certain value of PDR\n",
    "\n",
    "def corresponding_rssi_value(df,pdr):\n",
    "    test=df.loc[df['pdr']==pdr]\n",
    "    print('The median is: ',test['mean_rssi'].median())\n",
    "\n",
    "#corresponding_rssi_value(df,0.9)\n",
    "\n",
    "#Methods that help to draw the confusion matrix\n",
    "def trace_conf_mat(cm, acc,first,classes, norm, title,cmap=plt.cm.Blues):\n",
    "    accuracy=acc\n",
    "    if norm:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    chaine='Predicted label'\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title+'%.2f' % accuracy,\n",
    "           ylabel='True label',\n",
    "           xlabel=chaine)\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "     #        rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if norm else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_confusion_matrix_pdr(df, classes, cm,accuracy,first, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    trace_conf_mat(cm, accuracy,first,classes, normalize, title,cmap=plt.cm.Blues)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "#Split method, used to prepare classes for classification tasks\n",
    "\n",
    "def my_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] <= 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.80:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>0.3 and df['pdr'][i]<0.80)and df['mean_rssi'][i]<=-87):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] <= 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] <= -87 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>=-85 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    df=df.loc[(df['src']==src)&(df['dst']==dst)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "#Function that computes the Accuracy, the precision, the recall and the F1-Score given a confusion matrix\n",
    "\n",
    "def computer(cm,classes,path,type):\n",
    "    taill=len(cm)\n",
    "    \n",
    "\n",
    "    #We compute total for precision and recall\n",
    "    total_precision=list()#Total for precision\n",
    "    total_recall=list()#Total for recall\n",
    "    total=0#Total for accuracy\n",
    "    som=0#For accuracy\n",
    "    for j in range(taill):\n",
    "        total1=0\n",
    "        total2=0\n",
    "        som=som+cm[j][j]\n",
    "        for k in range(taill):\n",
    "            total1=total1+cm[j][k]\n",
    "            total2=total2+cm[k][j]\n",
    "            total=total+cm[j][k]\n",
    "            #print('Totally après: ',totali)\n",
    "            #print('cm[',j,'][',k,']: ',cm[j][k])\n",
    "        #print('Totally après: ',total1)\n",
    "        #print('Totally 2 après: ',total2)\n",
    "        total_precision.append(total1)\n",
    "        total_recall.append(total2)\n",
    "    accuracy=som/total\n",
    "        \n",
    "    #Value of precision and recall returned for each classes\n",
    "    import os\n",
    "    file_name=path+type+\"_final_result.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write('title,precision,recall,f1-score\\n')\n",
    "    \n",
    "    returner=list()\n",
    "    for i in range(taill):\n",
    "        precision=cm[i][i]/total_precision[i]\n",
    "        recall=cm[i][i]/total_recall[i]\n",
    "        f1_Score=2*(precision*recall)/(precision+recall)\n",
    "        vale='['+classes[i]+']: precision=%.2f' % precision+', recall=%.2f' %recall+', f1-score=%.2f'%f1_Score\n",
    "        file.write(str(classes[i])+','+str(precision)+','+str(recall)+','+str(f1_Score)+'\\n')\n",
    "    file.close()\n",
    "    returner.append(vale)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return accuracy,returner\n",
    "\n",
    "\n",
    "#Logistic regression Classification\n",
    "def my_logreg(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    text=\"\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LR/Log_Reg_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR/Log_Reg_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LR/Log_Reg_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR/Log_Reg_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LR/Log_Reg_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR/Log_Reg_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        #Classification over each channel of the link\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        classes2=labels.unique()\n",
    "        if len(classes2)>1:\n",
    "        #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "         #   labels=pd.Series(labels)\n",
    "\n",
    "         #The train_test_split() method works only if the number of classes for prediction is greather or aqual to 2\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "            taill=len(pd.Series(train_labels).unique())\n",
    "            if taill>1:\n",
    "                LogReg=LogisticRegression()\n",
    "                LogReg.fit(train_features,train_labels)\n",
    "                pred_labels=LogReg.predict(test_features)\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "            else:\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(test_labels)\n",
    "        else:\n",
    "            #If the number of class for classification is equal to one in a given channel of a link, we just report the corresponding value of classes in test_labels and pred_label, according to the size_test\n",
    "            test_tail=int(size_of_test*len(labels))\n",
    "            test_labels=list()\n",
    "            pred_labels=list()\n",
    "            labels=labels.to_numpy()\n",
    "            for j in range(test_tail):\n",
    "                test_labels.append(labels[j])\n",
    "                pred_labels.append(labels[j])\n",
    "            general_test_labels=general_test_labels+test_labels\n",
    "            general_pred_labels=general_pred_labels+pred_labels\n",
    "\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    chaine=\"lr_\"+kind\n",
    "    accuracy,returner=computer(cm,classes,path,chaine)\n",
    "    \n",
    "    #print(\"Returner:  \",returner)\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "#SVM Classification\n",
    "def my_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "            title=path+\"SVM/SVM_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM/SVM_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"SVM/SVM_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM/SVM_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"SVM/SVM_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM/SVM_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        classes2=labels.unique()\n",
    "        if len(classes2)>1:\n",
    "        #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "        #    labels=pd.Series(labels)\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "            taill=len(pd.Series(train_labels).unique())\n",
    "            if taill>1:\n",
    "                clf = SVC(random_state=0, tol=1e-5)\n",
    "                clf.fit(train_features, train_labels)\n",
    "                pred_labels=clf.predict(test_features)\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "            else:\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(test_labels)\n",
    "        else:\n",
    "        #If the number of class for classification is equal to one in a given channel of a link, we just report the corresponding value of classes in test_labels and pred_label, according to the size_test\n",
    "            test_tail=int(size_of_test*len(labels))\n",
    "            test_labels=list()\n",
    "            pred_labels=list()\n",
    "            labels=labels.to_numpy()\n",
    "            for j in range(test_tail):\n",
    "                test_labels.append(labels[j])\n",
    "                pred_labels.append(labels[j])\n",
    "            general_test_labels=general_test_labels+test_labels\n",
    "            general_pred_labels=general_pred_labels+pred_labels\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    chaine=\"svm_\"+kind\n",
    "    accuracy,returner=computer(cm,classes,path,chaine)\n",
    "    \n",
    "    #print(\"Returner:  \",returner)\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "#Linear SVM Classification\n",
    "def my_linear_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LSVM/LSVM_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM/LSVM_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LSVM/LSVM_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM/LSVM_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LSVM/LSVM_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM/LSVM_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        classes2=labels.unique()\n",
    "        if len(classes2)>1:\n",
    "        #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "         #   labels=pd.Series(labels)\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "            taill=len(pd.Series(train_labels).unique())\n",
    "            if taill>1:\n",
    "                clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "                clf.fit(train_features, train_labels)\n",
    "                pred_labels=clf.predict(test_features)\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "            else:\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(test_labels)\n",
    "        else:\n",
    "        #If the number of class for classification is equal to one in a given channel of a link, we just report the corresponding value of classes in test_labels and pred_label, according to the size_test\n",
    "            test_tail=int(size_of_test*len(labels))\n",
    "            test_labels=list()\n",
    "            pred_labels=list()\n",
    "            labels=labels.to_numpy()\n",
    "            for j in range(test_tail):\n",
    "                test_labels.append(labels[j])\n",
    "                pred_labels.append(labels[j])\n",
    "            general_test_labels=general_test_labels+test_labels\n",
    "            general_pred_labels=general_pred_labels+pred_labels\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    chaine=\"lsvm_\"+kind\n",
    "    accuracy,returner=computer(cm,classes,path,chaine)\n",
    "    \n",
    "    #print(\"Returner:  \",returner)\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "#Random Forest Classification\n",
    "def my_random_forest(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"RF/RF_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF/RF_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"RF/RF_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF/RF_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"RF/RF_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF/RF_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        classes2=labels.unique()\n",
    "        if len(classes2)>1:\n",
    "            #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "            #    labels=pd.Series(labels)\n",
    "            train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "            taill=len(pd.Series(train_labels).unique())\n",
    "            if taill>1:\n",
    "                rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "                rf.fit(train_features, train_labels)\n",
    "                pred_labels=rf.predict(test_features)\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "            else:\n",
    "                general_test_labels=general_test_labels+list(test_labels)\n",
    "                general_pred_labels=general_pred_labels+list(test_labels)\n",
    "        else:\n",
    "        #If the number of class for classification is equal to one in a given channel of a link, we just report the corresponding value of classes in test_labels and pred_label, according to the size_test\n",
    "            test_tail=int(size_of_test*len(labels))\n",
    "            test_labels=list()\n",
    "            pred_labels=list()\n",
    "            labels=labels.to_numpy()\n",
    "            for j in range(test_tail):\n",
    "                test_labels.append(labels[j])\n",
    "                pred_labels.append(labels[j])\n",
    "            general_test_labels=general_test_labels+test_labels\n",
    "            general_pred_labels=general_pred_labels+pred_labels\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    chaine=\"rf_\"+kind\n",
    "    accuracy,returner=computer(cm,classes,path,chaine)\n",
    "    \n",
    "    #print(\"Returner:  \",returner)\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy,returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "def executor(df,src, dst, size_of_test,model_list,path):\n",
    "    import os\n",
    "    file_name=path+\"final_results.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "        #file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    for i in model_list:\n",
    "        if i=='lr':\n",
    "            lg_all=my_logreg(df,src,dst,size_of_test,'all',path)\n",
    "            lg_pdr=my_logreg(df,src,dst,size_of_test,'pdr',path)\n",
    "            lg_rssi=my_logreg(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LogReg,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lg_all)+','+str(lg_pdr)+','+str(lg_rssi))\n",
    "        elif i=='lsvm':\n",
    "            lsvm_all=my_linear_svm(df,src,dst,size_of_test,'all',path)\n",
    "            lsvm_pdr=my_linear_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            lsvm_rssi=my_linear_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LSVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lsvm_all)+','+str(lsvm_pdr)+','+str(lsvm_rssi))\n",
    "        elif i=='svm':\n",
    "            svm_all=my_svm(df,src,dst,size_of_test,'all',path)\n",
    "            svm_pdr=my_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            svm_rssi=my_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'SVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(svm_all)+','+str(svm_pdr)+','+str(svm_rssi))\n",
    "        elif i=='rf':  \n",
    "            rf_all=my_random_forest(df,src,dst,size_of_test,'all',path)\n",
    "            rf_pdr=my_random_forest(df,src,dst,size_of_test,'pdr',path)\n",
    "            rf_rssi=my_random_forest(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'RF,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(rf_all)+','+str(rf_pdr)+','+str(rf_rssi))\n",
    "    file.close()\n",
    "\n",
    "#The following function aims to compute the accuracies of all the links in the network for all our methods\n",
    "def final_executor(df,size_of_test,my_execution_list,path):\n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            colonne=[\"pdr\"]\n",
    "            ts=df.loc[(df['src']==sender)&(df['dst']==receiver),colonne]\n",
    "            if len(ts)>0:\n",
    "                print(\"Starting link \",sender,\"===\",receiver)\n",
    "                executor(df,sender,receiver,size_of_test,my_execution_list,path)\n",
    "                print(\"Ending link \",sender,\"===\",receiver)\n",
    "\n",
    "def my_general_predictor(df,size_of_test,kind,path):#Kind can be \"pdr\", \"rssi\" or \"all\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        lr_title=path+\"LR_CM_ALL.png\"\n",
    "        lr_title2=path+\"LR_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=path+\"RF_CM_ALL.png\"\n",
    "        rf_title2=path+\"RF_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=path+\"SVM_CM_ALL.png\"\n",
    "        svm_title2=path+\"SVM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=path+\"LSVM_CM_ALL.png\"\n",
    "        lsvm_title2=path+\"LSVM_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        colonne=['combined_features']\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        lr_title=path+\"LR_CM_PDR.png\"\n",
    "        lr_title2=path+\"LR_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=path+\"RF_CM_PDR.png\"\n",
    "        rf_title2=path+\"RF_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=path+\"SVM_CM_PDR.png\"\n",
    "        svm_title2=path+\"SVM_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=path+\"LSVM_CM_PDR.png\"\n",
    "        lsvm_title2=path+\"LSVM_CM_PDR_Not_Normalized.png\"\n",
    "        colonne=['pdr']\n",
    "        \n",
    "    else:\n",
    "        lr_title=path+\"LR_CM_RSSI.png\"\n",
    "        lr_title2=path+\"LR_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=path+\"RF_CM_RSSI.png\"\n",
    "        rf_title2=path+\"RF_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=path+\"SVM_CM_RSSI.png\"\n",
    "        svm_title2=path+\"SVM_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=path+\"LSVM_CM_RSSI.png\"\n",
    "        lsvm_title2=path+\"LSVM_CM_RSSI_Not_Normalized.png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "        \n",
    "    lr_general_test_labels=list()\n",
    "    lr_general_pred_labels=list()  \n",
    "    \n",
    "    rf_general_test_labels=list()\n",
    "    rf_general_pred_labels=list()\n",
    "    \n",
    "    svm_general_test_labels=list()\n",
    "    svm_general_pred_labels=list()\n",
    "    \n",
    "    lsvm_general_test_labels=list()\n",
    "    lsvm_general_pred_labels=list()\n",
    "    \n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    import os\n",
    "    file_name=path+\"runner.txt\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "        #file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            ts=my_split(df,sender,receiver,size_of_test,kind)\n",
    "            if len(ts)>0:\n",
    "                print('stating link: ',sender,'==>',receiver)\n",
    "                file.write(str('\\n')+'starting link: '+str(sender)+'==>'+str(receiver))\n",
    "                \n",
    "                channel_list=ts['channel'].unique()\n",
    "                classes=ts['target_names'].unique()\n",
    "                for i in range (len(channel_list)):\n",
    "                    channel_i=channel_list[i]\n",
    "                    colonne2=['target_names']\n",
    "                    ts1=ts.loc[(ts['channel']==channel_i),colonne]\n",
    "                    ts2=ts.loc[(ts['channel']==channel_i),colonne2]\n",
    "\n",
    "                    features=ts1.values\n",
    "                    labels=ts2['target_names']\n",
    "                    classes2=labels.unique()\n",
    "                    if len(classes2)>1:\n",
    "                     #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "                     #   labels=pd.Series(labels)\n",
    "                        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=False)\n",
    "                        taill=len(pd.Series(train_labels).unique())\n",
    "                        if taill>1:\n",
    "                            LogReg=LogisticRegression()\n",
    "                            LogReg.fit(train_features,train_labels)\n",
    "                            lr_pred_labels=LogReg.predict(test_features)\n",
    "                            lr_general_test_labels=lr_general_test_labels+list(test_labels)\n",
    "                            lr_general_pred_labels=lr_general_pred_labels+list(lr_pred_labels)\n",
    "                            \n",
    "                            lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
    "                            lsvm.fit(train_features, train_labels)\n",
    "                            lsvm_pred_labels = lsvm.predict(test_features)\n",
    "                            lsvm_general_test_labels=lsvm_general_test_labels+list(test_labels)\n",
    "                            lsvm_general_pred_labels=lsvm_general_pred_labels+list(lsvm_pred_labels)\n",
    "                            \n",
    "                            svm = SVC(random_state=0, tol=1e-5)\n",
    "                            svm.fit(train_features, train_labels)\n",
    "                            svm_pred_labels = svm.predict(test_features)\n",
    "                            svm_general_test_labels=svm_general_test_labels+list(test_labels)\n",
    "                            svm_general_pred_labels=svm_general_pred_labels+list(svm_pred_labels)\n",
    "                            \n",
    "                            rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "                            rf.fit(train_features, train_labels)\n",
    "                            rf_pred_labels = rf.predict(test_features)\n",
    "                            rf_general_test_labels=rf_general_test_labels+list(test_labels)\n",
    "                            rf_general_pred_labels=rf_general_pred_labels+list(rf_pred_labels)\n",
    "                            \n",
    "                        else:\n",
    "                            lr_general_test_labels=lr_general_test_labels+list(test_labels)\n",
    "                            lr_general_pred_labels=lr_general_pred_labels+list(test_labels)\n",
    "                            \n",
    "                            rf_general_test_labels=rf_general_test_labels+list(test_labels)\n",
    "                            rf_general_pred_labels=rf_general_pred_labels+list(test_labels)\n",
    "                            \n",
    "                            svm_general_test_labels=svm_general_test_labels+list(test_labels)\n",
    "                            svm_general_pred_labels=svm_general_pred_labels+list(test_labels)\n",
    "                            \n",
    "                            lsvm_general_test_labels=lsvm_general_test_labels+list(test_labels)\n",
    "                            lsvm_general_pred_labels=lsvm_general_pred_labels+list(test_labels)\n",
    "                    else:\n",
    "                    #If the number of class for classification is equal to one in a given channel of a link, we just report the corresponding value of classes in test_labels and pred_label, according to the size_test\n",
    "                        test_tail=int(size_of_test*len(labels))\n",
    "                        test_labels=list()\n",
    "                        pred_labels=list()\n",
    "                        labels=labels.to_numpy()\n",
    "                        for j in range(test_tail):\n",
    "                            test_labels.append(labels[j])\n",
    "                            pred_labels.append(labels[j])\n",
    "\n",
    "                        lr_general_test_labels=lr_general_test_labels+test_labels\n",
    "                        lr_general_pred_labels=lr_general_pred_labels+pred_labels\n",
    "                        \n",
    "                        rf_general_test_labels=rf_general_test_labels+test_labels\n",
    "                        rf_general_pred_labels=rf_general_pred_labels+pred_labels\n",
    "                        \n",
    "                        svm_general_test_labels=svm_general_test_labels+test_labels\n",
    "                        svm_general_pred_labels=svm_general_pred_labels+pred_labels\n",
    "                        \n",
    "                        lsvm_general_test_labels=lsvm_general_test_labels+test_labels\n",
    "                        lsvm_general_pred_labels=lsvm_general_pred_labels+pred_labels\n",
    "                print('ending link: ',sender,'==>',receiver)\n",
    "                file.write(str('\\n')+'ending link: '+str(sender)+'==>'+str(receiver))\n",
    "    file.close()\n",
    "    lr_cm=confusion_matrix(lr_general_test_labels,lr_general_pred_labels)\n",
    "    \n",
    "    svm_cm=confusion_matrix(svm_general_test_labels,svm_general_pred_labels)\n",
    "    \n",
    "    lsvm_cm=confusion_matrix(lsvm_general_test_labels,lsvm_general_pred_labels)\n",
    "    \n",
    "    rf_cm=confusion_matrix(rf_general_test_labels,rf_general_pred_labels)\n",
    "    chaine=\"lr_\"+kind\n",
    "    lr_accuracy,lr_returner=computer(lr_cm,classes,path,chaine)\n",
    "    chaine=\"lsvm_\"+kind\n",
    "    lsvm_accuracy,lsvm_returner=computer(lsvm_cm,classes,path,chaine)\n",
    "    chaine=\"svm_\"+kind\n",
    "    svm_accuracy,svm_returner=computer(svm_cm,classes,path,chaine)\n",
    "    chaine=\"rf_\"+kind\n",
    "    rf_accuracy,rf_returner=computer(rf_cm,classes,path,chaine)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,lr_cm,lr_accuracy,lr_returner, normalize=True,title=subtitle)\n",
    "    plt.savefig(lr_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,rf_cm,rf_accuracy,rf_returner, normalize=True,title=subtitle)\n",
    "    plt.savefig(rf_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,lsvm_cm,lsvm_accuracy,lsvm_returner, normalize=True,title=subtitle)\n",
    "    plt.savefig(lsvm_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,svm_cm,svm_accuracy,svm_returner, normalize=True,title=subtitle)    \n",
    "    plt.savefig(svm_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,lr_cm,lr_accuracy,lr_returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(lr_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,lsvm_cm,lsvm_accuracy,lsvm_returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(lsvm_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,svm_cm,svm_accuracy,svm_returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(svm_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes,rf_cm,rf_accuracy,rf_returner, normalize=False,title=subtitle)\n",
    "    plt.savefig(rf_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "          \n",
    "    return lr_accuracy,lsvm_accuracy,rf_accuracy,svm_accuracy\n",
    "\n",
    "\n",
    "path=\"/home/sindjoung/Bureau/dev/GENERAL/\"\n",
    "#path=\"/home/rioc/mfokosin/camerSimulations/GENERAL/\"\n",
    "my_execution_list=['lr', 'lsvm','svm','rf']\n",
    "my_execution_list1=['lr']\n",
    "\n",
    "#executor(df,19, 44, 0.25,my_execution_list,path)\n",
    "#my_random_forest(df,19, 44, 0.25,\"all\",path)\n",
    "#my_svm(df,19, 44, 0.25,\"all\",path)\n",
    "#my_logreg(df,19, 44, 0.25,\"all\",path)\n",
    "#my_linear_svm(df,19, 44, 0.25,\"all\",path)\n",
    "my_general_predictor(df,0.25,\"pdr\",path)\n",
    "my_general_predictor(df,0.25,\"all\",path)\n",
    "my_general_predictor(df,0.25,\"rssi\",path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}