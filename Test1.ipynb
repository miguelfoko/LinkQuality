{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "import MyAnalysis \n",
    "rcParams['figure.figsize'] = 3,3\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_71.k7\",sep = ',',header = 0)\n",
    "\n",
    "def trace_conf_mat(cm, acc,classes, norm, title,cmap=plt.cm.Blues):\n",
    "    accuracy=acc\n",
    "    if norm:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title+'%.2f' % accuracy,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "     #        rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if norm else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_confusion_matrix_pdr(df, classes, cm,accuracy, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    trace_conf_mat(cm, accuracy,classes, normalize, title,cmap=plt.cm.Blues)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "def my_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] <= 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>0.3 and df['pdr'][i]<0.75)and df['mean_rssi'][i]<=-87):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] <= 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] <= -87 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>=-85 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    df=df.loc[(df['src']==src)&(df['dst']==dst)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#Logistic regression Classification\n",
    "def my_logreg(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    text=\"\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LR\\\\Log_Reg_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LR\\\\Log_Reg_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LR\\\\Log_Reg_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        #classes=labels.unique()\n",
    "        #if len(classes)>1:\n",
    "         #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "         #   labels=pd.Series(labels)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            LogReg=LogisticRegression()\n",
    "            LogReg.fit(train_features,train_labels)\n",
    "            pred_labels=LogReg.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "#SVM Classification\n",
    "def my_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "            title=path+\"SVM\\\\SVM_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"SVM\\\\SVM_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM\\\\SVM_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"SVM\\\\SVM_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM\\\\SVM_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        #classes=labels.unique()\n",
    "        #if len(classes)>1:\n",
    "        #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "        #    labels=pd.Series(labels)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            clf = SVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(train_features, train_labels)\n",
    "            pred_labels=clf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "#Linear SVM Classification\n",
    "def my_linear_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LSVM\\\\LSVM_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LSVM\\\\LSVM_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LSVM\\\\LSVM_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        #classes=labels.unique()\n",
    "        #if len(classes)>1:\n",
    "        #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "         #   labels=pd.Series(labels)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(train_features, train_labels)\n",
    "            pred_labels=clf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "#Random Forest Classification\n",
    "def my_random_forest(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"RF\\\\RF_CM_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_ALL_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"RF\\\\RF_CM_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_PDR_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"RF\\\\RF_CM_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_RSSI_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        #classes=labels.unique()\n",
    "        #if len(classes)>1:\n",
    "        #    features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "        #    labels=pd.Series(labels)\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "            rf.fit(train_features, train_labels)\n",
    "            pred_labels=rf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def executor(df,src, dst, size_of_test,model_list,path):\n",
    "    import os\n",
    "    file_name=path+\"final_results.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "        #file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    for i in model_list:\n",
    "        if i=='lr':\n",
    "            lg_all=my_logreg(df,src,dst,size_of_test,'all',path)\n",
    "            lg_pdr=my_logreg(df,src,dst,size_of_test,'pdr',path)\n",
    "            lg_rssi=my_logreg(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LogReg,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lg_all)+','+str(lg_pdr)+','+str(lg_rssi))\n",
    "        elif i=='lsvm':\n",
    "            lsvm_all=my_linear_svm(df,src,dst,size_of_test,'all',path)\n",
    "            lsvm_pdr=my_linear_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            lsvm_rssi=my_linear_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LSVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lsvm_all)+','+str(lsvm_pdr)+','+str(lsvm_rssi))\n",
    "        elif i=='svm':\n",
    "            svm_all=my_svm(df,src,dst,size_of_test,'all',path)\n",
    "            svm_pdr=my_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            svm_rssi=my_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'SVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(svm_all)+','+str(svm_pdr)+','+str(svm_rssi))\n",
    "        elif i=='rf':  \n",
    "            rf_all=my_random_forest(df,src,dst,size_of_test,'all',path)\n",
    "            rf_pdr=my_random_forest(df,src,dst,size_of_test,'pdr',path)\n",
    "            rf_rssi=my_random_forest(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'RF,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(rf_all)+','+str(rf_pdr)+','+str(rf_rssi))\n",
    "    file.close()\n",
    "        \n",
    "        \n",
    "#The following function aims to compute the accuracies of all the links in the network for all our methods\n",
    "def final_executor(df,size_of_test,my_execution_list,path):\n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            colonne=[\"pdr\"]\n",
    "            ts=df.loc[(df['src']==sender)&(df['dst']==receiver),colonne]\n",
    "            if len(ts)>0:\n",
    "                print(\"Starting link \",sender,\"===\",receiver)\n",
    "                executor(df,sender,receiver,size_of_test,my_execution_list,path)\n",
    "                print(\"Ending link \",sender,\"===\",receiver)\n",
    "\n",
    "                \n",
    "def my_general_predictor(df,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        lr_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL.png\"\n",
    "        lr_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL.png\"\n",
    "        rf_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_ALL.png\"\n",
    "        svm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_ALL.png\"\n",
    "        lsvm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "        colonne=['combined_features']\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        lr_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR.png\"\n",
    "        lr_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR.png\"\n",
    "        rf_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_PDR.png\"\n",
    "        svm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_PDR.png\"\n",
    "        lsvm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_PDR_Not_Normalized.png\"\n",
    "        colonne=['pdr']\n",
    "        \n",
    "    else:\n",
    "        lr_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI.png\"\n",
    "        lr_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        rf_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI.png\"\n",
    "        rf_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        svm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_RSSI.png\"\n",
    "        svm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "        lsvm_title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_RSSI.png\"\n",
    "        lsvm_title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_RSSI_Not_Normalized.png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "        \n",
    "    lr_general_test_labels=list()\n",
    "    lr_general_pred_labels=list()  \n",
    "    \n",
    "    rf_general_test_labels=list()\n",
    "    rf_general_pred_labels=list()\n",
    "    \n",
    "    svm_general_test_labels=list()\n",
    "    svm_general_pred_labels=list()\n",
    "    \n",
    "    lsvm_general_test_labels=list()\n",
    "    lsvm_general_pred_labels=list()\n",
    "    \n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            ts=my_split(df,sender,receiver,size_of_test,kind)\n",
    "            if len(ts)>0:\n",
    "                print('stating link: ',sender,'==>',receiver)\n",
    "                channel_list=ts['channel'].unique()\n",
    "                classes=ts['target_names'].unique()\n",
    "                for i in range (len(channel_list)):\n",
    "                    channel_i=channel_list[i]\n",
    "                    colonne2=['target_names']\n",
    "                    ts1=ts.loc[(ts['channel']==channel_i),colonne]\n",
    "                    ts2=ts.loc[(ts['channel']==channel_i),colonne2]\n",
    "\n",
    "                    features=ts1.values\n",
    "                    labels=ts2['target_names']\n",
    "                    #classes=labels.unique()\n",
    "                    #if len(classes)>1:\n",
    "                     #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "                     #   labels=pd.Series(labels)\n",
    "                    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "                    taill=len(pd.Series(train_labels).unique())\n",
    "                    if taill>1:\n",
    "                        LogReg=LogisticRegression()\n",
    "                        LogReg.fit(train_features,train_labels)\n",
    "                        lr_pred_labels=LogReg.predict(test_features)\n",
    "                        lr_general_test_labels=lr_general_test_labels+list(test_labels)\n",
    "                        lr_general_pred_labels=lr_general_pred_labels+list(lr_pred_labels)\n",
    "                        \n",
    "                        lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
    "                        lsvm.fit(train_features, train_labels)\n",
    "                        lsvm_pred_labels = clf.predict(test_features)\n",
    "                        lsvm_general_test_labels=lsvm_general_test_labels+list(test_labels)\n",
    "                        lsvm_general_pred_labels=lsvm_general_pred_labels+list(lsvm_pred_labels)\n",
    "                        \n",
    "                        svm = SVC(random_state=0, tol=1e-5)\n",
    "                        svm.fit(train_features, train_labels)\n",
    "                        svm_pred_labels = clf.predict(test_features)\n",
    "                        svm_general_test_labels=svm_general_test_labels+list(test_labels)\n",
    "                        svm_general_pred_labels=svm_general_pred_labels+list(svm_pred_labels)\n",
    "                        \n",
    "                        rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "                        rf.fit(train_features, train_labels)\n",
    "                        rf_pred_labels = clf.predict(test_features)\n",
    "                        rf_general_test_labels=rf_general_test_labels+list(test_labels)\n",
    "                        rf_general_pred_labels=rf_general_pred_labels+list(rf_pred_labels)\n",
    "                        \n",
    "                    else:\n",
    "                        lr_general_test_labels=lr_general_test_labels+list(test_labels)\n",
    "                        lr_general_pred_labels=lr_general_pred_labels+list(test_labels)\n",
    "                        \n",
    "                        rf_general_test_labels=rf_general_test_labels+list(test_labels)\n",
    "                        rf_general_pred_labels=rf_general_pred_labels+list(test_labels)\n",
    "                        \n",
    "                        svm_general_test_labels=svm_general_test_labels+list(test_labels)\n",
    "                        svm_general_pred_labels=svm_general_pred_labels+list(test_labels)\n",
    "                        \n",
    "                        lsvm_general_test_labels=lsvm_general_test_labels+list(test_labels)\n",
    "                        lsvm_general_pred_labels=lsvm_general_pred_labels+list(test_labels)\n",
    "                print('ending link: ',sender,'==>',receiver)\n",
    "    lr_cm=confusion_matrix(lr_general_test_labels,lr_general_pred_labels)\n",
    "    \n",
    "    svm_cm=confusion_matrix(svm_general_test_labels,svm_general_pred_labels)\n",
    "    \n",
    "    lsvm_cm=confusion_matrix(lsvm_general_test_labels,lsvm_general_pred_labels)\n",
    "    \n",
    "    rf_cm=confusion_matrix(rf_general_test_labels,rf_general_pred_labels)\n",
    "    \n",
    "    lr_som,rf_som,svm_som,lsvm_som=0\n",
    "    taill=len(lr_cm)\n",
    "    lr_total=0\n",
    "    for i in range(taill):\n",
    "        lr_som=lr_som+lr_cm[i][i]\n",
    "        svm_som=svm_som+svm_cm[i][i]\n",
    "        lsvm_som=lsvm_som+lsvm_cm[i][i]\n",
    "        rf_som=rf_som+rf_cm[i][i]\n",
    "        \n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    lr_accuracy=lr_som/total\n",
    "    lsvm_accuracy=lsvm_som/total\n",
    "    svm_accuracy=svm_som/total\n",
    "    rf_accuracy=rf_som/total\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,lr_cm,lr_accuracy, normalize=True,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,rf_cm,rf_accuracy, normalize=True,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,lsvm_cm,lsvm_accuracy, normalize=True,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,svm_cm,svm_accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(lr_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(lsvm_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(svm_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(rf_title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,lr_cm,lr_accuracy, normalize=False,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,lsvm_cm,lsvm_accuracy, normalize=False,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,svm_cm,svm_accuracy, normalize=False,title=subtitle)\n",
    "    plot_confusion_matrix_pdr(df, classes,rf_cm,rf_accuracy, normalize=False,title=subtitle)\n",
    "    \n",
    "    plt.savefig(lr_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(lsvm_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(svm_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.savefig(rf_title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "path=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\\"\n",
    "my_execution_list=['lr', 'lsvm','svm','rf']\n",
    "my_execution_list1=['lr']\n",
    "\n",
    "my_general_predictor(df,0.25,\"all\",path)\n",
    "\n",
    "#executor(df,2, 47, 0.25,my_execution_list,path)\n",
    "#executor(df,3, 15, 0.25,my_execution_list,path)\n",
    "#final_executor(df,0.25,my_execution_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
