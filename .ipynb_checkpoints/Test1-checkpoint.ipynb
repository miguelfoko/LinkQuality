{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974025974025974"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "import MyAnalysis \n",
    "\n",
    "from MyAnalysis import plot_confusion_matrix_pdr\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "\n",
    "def my_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] < 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>=0.3 and df['pdr'][i]<=0.75)and df['mean_rssi'][i]<-70):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] < 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] < -70 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>-40 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    df=df.loc[(df['src']==src)&(df['dst']==dst)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#Logistic regression Classification\n",
    "def my_logreg(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    text=\"\"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LR\\\\Log_Reg_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LogReg PDR+RSSI= \"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LR\\\\Log_Reg_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LogReg PDR= \"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LR\\\\Log_Reg_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LogReg RSSI= \"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            LogReg=LogisticRegression()\n",
    "            LogReg.fit(train_features,train_labels)\n",
    "            pred_labels=LogReg.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "#SVM Classification\n",
    "def my_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    if kind==\"all\":\n",
    "            title=path+\"SVM\\\\SVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM PDR+RSSI= \"\n",
    "            colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"SVM\\\\SVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM\\\\SVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of SVM PDR= \"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"SVM\\\\SVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"SVM\\\\SVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of SVM RSSI= \"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            clf = SVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(train_features, train_labels)\n",
    "            pred_labels=clf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "#Linear SVM Classification\n",
    "def my_linear_svm(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    if kind==\"all\":\n",
    "        title=path+\"LSVM\\\\LSVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LSVM PDR+RSSI= \"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"LSVM\\\\LSVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LSVM PDR= \"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"LSVM\\\\LSVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of LSVM RSSI= \"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(train_features, train_labels)\n",
    "            pred_labels=clf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "#Random Forest Classification\n",
    "def my_random_forest(df1,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    df=my_split(df1,src,dst,size_of_test,kind)\n",
    "    if kind==\"all\":\n",
    "        title=path+\"RF\\\\RF_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of RF PDR+RSSI= \"\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"RF\\\\RF_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of RF PDR= \"\n",
    "        colonne=['pdr']\n",
    "    else:\n",
    "        title=path+\"RF\\\\RF_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title2=path+\"RF\\\\RF_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        subtitle=\"Accuracy of RF RSSI= \"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()\n",
    "    channel_list=df1['channel'].unique()\n",
    "    classes=df['target_names'].unique()\n",
    "    accuracy_results=list()\n",
    "    for i in range (len(channel_list)):\n",
    "        channel_i=channel_list[i]\n",
    "        colonne2=['target_names']\n",
    "        ts=df.loc[(df['channel']==channel_i),colonne]\n",
    "        ts2=df.loc[(df['channel']==channel_i),colonne2]\n",
    "\n",
    "        features=ts.values\n",
    "        labels=ts2['target_names']\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "        taill=len(pd.Series(train_labels).unique())\n",
    "        if taill>1:\n",
    "            rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "            rf.fit(train_features, train_labels)\n",
    "            pred_labels=rf.predict(test_features)\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "        else:\n",
    "            general_test_labels=general_test_labels+list(test_labels)\n",
    "            general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "def executor(df,src, dst, size_of_test,model_list,path):\n",
    "    import os\n",
    "    file_name=path+\"results1.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "        #file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    for i in model_list:\n",
    "        if i=='lr':\n",
    "            lg_all=my_logreg(df,src,dst,size_of_test,'all',path)\n",
    "            lg_pdr=my_logreg(df,src,dst,size_of_test,'pdr',path)\n",
    "            lg_rssi=my_logreg(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LogReg,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lg_all)+','+str(lg_pdr)+','+str(lg_rssi))\n",
    "        elif i=='lsvm':\n",
    "            lsvm_all=my_linear_svm(df,src,dst,size_of_test,'all',path)\n",
    "            lsvm_pdr=my_linear_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            lsvm_rssi=my_linear_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LSVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lsvm_all)+','+str(lsvm_pdr)+','+str(lsvm_rssi))\n",
    "        elif i=='svm':\n",
    "            svm_all=my_svm(df,src,dst,size_of_test,'all',path)\n",
    "            svm_pdr=my_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            svm_rssi=my_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'SVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(svm_all)+','+str(svm_pdr)+','+str(svm_rssi))\n",
    "        elif i=='rf':  \n",
    "            rf_all=my_random_forest(df,src,dst,size_of_test,'all',path)\n",
    "            rf_pdr=my_random_forest(df,src,dst,size_of_test,'pdr',path)\n",
    "            rf_rssi=my_random_forest(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'RF,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(rf_all)+','+str(rf_pdr)+','+str(rf_rssi))\n",
    "    file.close()\n",
    "        \n",
    "        \n",
    "#The following function aims to compute the accuracies of all the links in the network for all our methods\n",
    "def final_executor(df,size_of_test,my_execution_list,path):\n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            colonne=[\"pdr\"]\n",
    "            ts=df.loc[(df['src']==sender)&(df['dst']==receiver),colonne]\n",
    "            if len(ts)>0:\n",
    "                print(\"Starting link \",sender,\"===\",receiver)\n",
    "                executor(df,sender,receiver,size_of_test,my_execution_list,path)\n",
    "                print(\"Ending link \",sender,\"===\",receiver)\n",
    "\n",
    "path=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\ALL2\\\\\"\n",
    "my_execution_list=['lr', 'lsvm','svm','rf']\n",
    "#final_executor(df,0.25,my_execution_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
