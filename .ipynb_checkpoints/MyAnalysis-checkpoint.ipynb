{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([       model     link  test_size  accuracy_with_pdr_and_rssi  \\\n",
      "0     LogReg   0===18       0.25                    0.000000   \n",
      "4     LogReg    0===7       0.25                    0.000000   \n",
      "8     LogReg   0===42       0.25                    0.000000   \n",
      "12    LogReg   0===28       0.25                    0.000000   \n",
      "16    LogReg   0===12       0.25                    0.000000   \n",
      "...      ...      ...        ...                         ...   \n",
      "1888  LogReg  49===43       0.25                    0.000000   \n",
      "1892  LogReg   49===0       0.25                   -1.000000   \n",
      "1896  LogReg  49===37       0.25                    0.000000   \n",
      "1900  LogReg  49===33       0.25                   -1.000000   \n",
      "1904  LogReg  49===13       0.25                    0.708661   \n",
      "\n",
      "      accuracy_with_pdr  accuracy_with_rssi  \n",
      "0              1.000000            1.000000  \n",
      "4              0.000000            0.000000  \n",
      "8              1.000000           -1.000000  \n",
      "12             1.000000            0.000000  \n",
      "16             0.982609            0.385321  \n",
      "...                 ...                 ...  \n",
      "1888           1.000000           -1.000000  \n",
      "1892           0.000000           -1.000000  \n",
      "1896           1.000000            0.000000  \n",
      "1900          -1.000000            0.763780  \n",
      "1904           0.000000           -1.000000  \n",
      "\n",
      "[477 rows x 6 columns],      model     link  test_size  accuracy_with_pdr_and_rssi  accuracy_with_pdr  \\\n",
      "1     LSVM   0===18       0.25                         0.0           1.000000   \n",
      "5     LSVM    0===7       0.25                         0.0           1.000000   \n",
      "9     LSVM   0===42       0.25                         0.0           1.000000   \n",
      "13    LSVM   0===28       0.25                         0.0           1.000000   \n",
      "17    LSVM   0===12       0.25                         0.0           1.000000   \n",
      "...    ...      ...        ...                         ...                ...   \n",
      "1889  LSVM  49===43       0.25                         1.0           1.000000   \n",
      "1893  LSVM   49===0       0.25                        -1.0           1.000000   \n",
      "1897  LSVM  49===37       0.25                         1.0           1.000000   \n",
      "1901  LSVM  49===33       0.25                        -1.0          -1.000000   \n",
      "1905  LSVM  49===13       0.25                         0.0           0.257895   \n",
      "\n",
      "      accuracy_with_rssi  \n",
      "1                    1.0  \n",
      "5                    1.0  \n",
      "9                   -1.0  \n",
      "13                   1.0  \n",
      "17                   1.0  \n",
      "...                  ...  \n",
      "1889                -1.0  \n",
      "1893                -1.0  \n",
      "1897                 1.0  \n",
      "1901                 0.0  \n",
      "1905                -1.0  \n",
      "\n",
      "[477 rows x 6 columns],      model     link  test_size  accuracy_with_pdr_and_rssi  accuracy_with_pdr  \\\n",
      "2      SVM   0===18       0.25                    1.000000                1.0   \n",
      "6      SVM    0===7       0.25                    1.000000                1.0   \n",
      "10     SVM   0===42       0.25                    0.952756                1.0   \n",
      "14     SVM   0===28       0.25                    1.000000                1.0   \n",
      "18     SVM   0===12       0.25                    1.000000                1.0   \n",
      "...    ...      ...        ...                         ...                ...   \n",
      "1890   SVM  49===43       0.25                    1.000000                1.0   \n",
      "1894   SVM   49===0       0.25                   -1.000000                1.0   \n",
      "1898   SVM  49===37       0.25                    1.000000                1.0   \n",
      "1902   SVM  49===33       0.25                   -1.000000               -1.0   \n",
      "1906   SVM  49===13       0.25                    0.937008                1.0   \n",
      "\n",
      "      accuracy_with_rssi  \n",
      "2                    1.0  \n",
      "6                    1.0  \n",
      "10                  -1.0  \n",
      "14                   1.0  \n",
      "18                   1.0  \n",
      "...                  ...  \n",
      "1890                -1.0  \n",
      "1894                -1.0  \n",
      "1898                 1.0  \n",
      "1902                 1.0  \n",
      "1906                -1.0  \n",
      "\n",
      "[477 rows x 6 columns],      model     link  test_size  accuracy_with_pdr_and_rssi  accuracy_with_pdr  \\\n",
      "3       RF   0===18       0.25                    1.000000                1.0   \n",
      "7       RF    0===7       0.25                    0.666667                1.0   \n",
      "11      RF   0===42       0.25                    0.968504                1.0   \n",
      "15      RF   0===28       0.25                    1.000000                1.0   \n",
      "19      RF   0===12       0.25                    1.000000                1.0   \n",
      "...    ...      ...        ...                         ...                ...   \n",
      "1891    RF  49===43       0.25                    1.000000                1.0   \n",
      "1895    RF   49===0       0.25                   -1.000000                1.0   \n",
      "1899    RF  49===37       0.25                    1.000000                1.0   \n",
      "1903    RF  49===33       0.25                   -1.000000               -1.0   \n",
      "1907    RF  49===13       0.25                    0.960630                1.0   \n",
      "\n",
      "      accuracy_with_rssi  \n",
      "3                    1.0  \n",
      "7                    1.0  \n",
      "11                  -1.0  \n",
      "15                   1.0  \n",
      "19                   1.0  \n",
      "...                  ...  \n",
      "1891                -1.0  \n",
      "1895                -1.0  \n",
      "1899                 1.0  \n",
      "1903                 1.0  \n",
      "1907                -1.0  \n",
      "\n",
      "[477 rows x 6 columns]], [477, 477, 477, 477], [32, 67, 104, 1], [274, 252, 139, 181], [171, 158, 234, 295])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "#rcParams['figure.figsize']=5,4\n",
    "#sb.set_style('whitegrid')\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "class_names=['Bad','Intermediate','Good']\n",
    "#print(type(df))\n",
    "#print(df.shape)#Affiche le nombre de ligne et le nombre de colonne de mon fichier\n",
    "#test=df.head(15)#Affiche les premières lignes du fichier (les ( premières))\n",
    "#print(df.columns)#Affiche toutes les colonnes du fichier(leur nom)\n",
    "#print(df.dtypes)#Affiche les noms des colones et leurs types\n",
    "#print(df.info())#Affiche les informations complémentaires sur chacun des champs (nombre d'occurence, type, ...)\n",
    "#test=df['mean_rssi'].describe()#Affiche les éléments de la statistique descriptive de la colonne donnée \n",
    "#test=df['datetime'].sort_values()#Permet de trier les données sélectionnées\n",
    "#test=df.iloc[0:10,:]#Affiche les 10 première lignes de mon fichier\n",
    "#test=df.iloc[0:10,[0,3,4,5]]#Affiche les colonnes 0, 3, 4 ert 5 des 10 premières lignes de mes données\n",
    "#test=df.loc[df['src']==0,:]#Affiche uniquement les lignes où le src=0\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),:]//Affiche uniquement les lignes dont src=0 et channel=11\n",
    "#colonne=['datetime', 'src', 'dst', 'channel', 'mean_rssi', 'pdr']\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),colonne]#Affiche les ligne dont src=0 et channel=11. N'affiche que les colonnes mentionnées dans le tableau \"colonne\"\n",
    "#df.hist(column='mean_rssi')#Trace l'histogramme de la colonne \"mean_rssi\"\n",
    "#df['mean_rssi'].plot.kde()#Permet de tracer la courbe des densité sur mean_rssi\n",
    "#df.hist(column='mean_rssi',by='channel')#Trace l'histogramme de lean_rssi en fonction de channel\n",
    "#test = pd.date_range(start='1/1/2018', end='1/12/2018', freq='D')\n",
    "\n",
    "#df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')#Convertie les données de la colone 'datetime' en type date\n",
    "#df=df.set_index('datetime')\n",
    "#df.hist(column='mean_rssi',by='datetime')\n",
    "target_count=df.channel.value_counts()\n",
    "\n",
    "labels = df.columns[5]\n",
    "\n",
    "X = df[labels]\n",
    "y = df['pdr']\n",
    "\n",
    " \n",
    "    \n",
    "def plot_ar4(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(2,1,0))\n",
    "    results_AR=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_AR.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\AR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "        \n",
    "def plot_ma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(0,1,2))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\MA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "def plot_arima(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(1,0,1))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\ARIMA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_arma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df['pdr']\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    res=model.fit(disp=-1)\n",
    "    plt.plot(ts)\n",
    "    plt.plot(res.fittedvalues,color='red')\n",
    "    #plt.title('RSS: %.4f'% sum((res.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\ARMA1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    res= res.predict()\n",
    "\n",
    "    \n",
    "    #plt.ylabel('Baysian Information Criterion')\n",
    "    #plt.plot(res)\n",
    "    #plt.show()\n",
    "    print(\"According to Baysian Information criteria, we can use (ARMA(3,0) model)\")\n",
    "    print (\"min: \",ts.index.min())\n",
    "    print (\"max: \",ts.index.max())\n",
    "    \n",
    "def plot_test(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    df.index = df.index.to_period('H')\n",
    "    #dep = df[[\"channel\",\"pdr\"]].groupby(\"channel\", as_index=True).mean()\n",
    "    nb=df.index.unique()\n",
    "    print(\"Nb de date= \",len(nb))\n",
    "    ts=df['pdr']\n",
    "    print(ts)\n",
    "\n",
    "    \n",
    "def plot_test2(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df.loc[(df['channel']==11)]\n",
    "    ts=ts['pdr']\n",
    "    print(len(ts))\n",
    "    plt.plot(ts)\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    model_fit=model.fit(disp=0)\n",
    "    print(model_fit.summary())\n",
    "    plt.plot(ts)\n",
    "    pred=model_fit.forecast()\n",
    "    plt.plot(pred[0],color='blue')\n",
    "    plt.title('ARMA(1,1) On channel ',11,' With accuracy: ')\n",
    "    plt.savefig(\"ARMA\\ARMA_Chanel11_1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "\n",
    "def stationarity(ts,seuil):\n",
    "    tsa=np.exp(ts)\n",
    "    rolmean=tsa.rolling(window=1).mean()\n",
    "    rolstd=tsa.rolling(1).std()\n",
    "    \n",
    "    print('rolling_mean: ',rolmean)\n",
    "    #print('rolstd_mean: ',rolstd)\n",
    "    \n",
    "    ts1=ts-rolmean\n",
    "    ts1.dropna(inplace=True)\n",
    "    plt.plot(ts1,color='black')\n",
    "    \n",
    "    ts2=ts-rolstd\n",
    "    ts2.dropna(inplace=True)\n",
    "    plt.plot(ts2,color='yellow')\n",
    "    \n",
    "    plt.plot(ts,color='red')\n",
    "    results = adfuller(ts2, autolag='AIC')\n",
    "    print('ADF Statistic: ', results[0])\n",
    "    print('P-Value: ',results[1])\n",
    "    print('Critical values: ')\n",
    "    for key,value in results[4].items():\n",
    "        print('\\t ',key,': %.3f'%(value))\n",
    "\n",
    "        \n",
    "def channel_in_a_link(df,src,dst):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')\n",
    "    df=df.set_index('datetime')\n",
    "    color_list = [\"blue\", \"red\"]\n",
    "    \n",
    "    \n",
    "    ts=df.loc[(df['src']==src)&((df['dst']==dst))]\n",
    "    #ts=ts.loc[((ts['src']==src)&(ts['dst']==dst))|((ts['src']==dst)&(ts['dst']==src))]\n",
    "    #ts=ts.loc[(ts['src']==src)&(ts['dst']==dst)]\n",
    "    for link, df_link in ts.groupby([\"src\"]):\n",
    "        #dep = df_link[[\"channel\",\"pdr\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #dep = df_link[[\"channel\",\"mean_rssi\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #print(dep)\n",
    "        for ln,ln1 in df_link.groupby(\"channel\"):\n",
    "            #print(ln1)\n",
    "            plt.plot(ln1.index, 0.95*ln1.mean_rssi / 100 + ln,\n",
    "            #plt.plot(ln1.index, 0.8 * ln1.pdr + ln,\n",
    "                          '-', zorder=1, markersize=2,\n",
    "                          color=color_list[ln%len(color_list)])\n",
    "        #print(ln1.channel)\n",
    "        day1_start = pd.to_datetime(\"2018-01-11 22:00:00.000\")\n",
    "        day1_stop = pd.to_datetime(\"2018-01-12 06:00:00.000\")\n",
    "        plt.fill_between([day1_start, day1_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        day2_start = pd.to_datetime(\"2018-01-12 22:00:00.000\")\n",
    "        day2_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        plt.fill_between([day2_start, day2_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        #day3_start = pd.to_datetime(\"2018-01-13 20:00:00.000\")\n",
    "        #day3_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        #plt.fill_between([day3_start, day3_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        #plt.ylabel('PDR (%) per IEEE802.15.4 Channel')\n",
    "        plt.ylabel('Average RSSI (dBm) per IEEE802.15.4 Channel')\n",
    "        plt.ylim([10, 27])\n",
    "        plt.yticks(df.channel.unique())\n",
    "        #plt.xticks(df.index.unique())\n",
    "        plt.grid(True)\n",
    "        #xfmt = md.DateFormatter('%H:%M:%s')\n",
    "        #xfmt = md.DateFormatter('%M:%S')\n",
    "        xfmt = md.DateFormatter('%Y-%m-%d %H')\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(xfmt)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        #plt.savefig(\"time_pdr\\pdr_time_per_channel_{0}.png\".format(link), format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "def general_channel_in_link(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                channel_in_a_link(df,i,j)\n",
    "        \n",
    "def spaguetti_plot_pdr(df,channel):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    ts=df['pdr']\n",
    "    #ts=df['mean_rssi']\n",
    "    \n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    ts=df.loc[(df['channel']==channel)]\n",
    "    plt.plot(ts,color='red')\n",
    "    plt.ylim(0, 1)\n",
    "    #plt.ylim(-100, 0)\n",
    "\n",
    "    #plt.xlabel('PDR')\n",
    "    plt.xlabel('Time')\n",
    "    #plt.ylabel('MEAN RSSI')\n",
    "    plt.ylabel('PDR')\n",
    "    plt.title('PDR spaguetti plot by channel')\n",
    "    plt.grid(True)\n",
    "\n",
    "    #plt.show()\n",
    "    title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_spaguethiPlot.png\"\n",
    "    #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_spaguethiPlot.png\"\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.savefig(\"PDR_BY_RSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def min_max(df):\n",
    "    mini=list()\n",
    "    maxi=list()\n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    for i in channel_list:\n",
    "        ts=df.loc[(df['channel']==i)]\n",
    "        mini.append(min(ts['pdr'])*1)\n",
    "        maxi.append(max(ts['pdr'])*1)\n",
    "        \n",
    "    print('Mini:===>',mini)\n",
    "    print(\"Maxi:===>\",maxi)\n",
    "    print('channel_List:==>',channel_list)\n",
    "    plt.hist(mini)\n",
    "    #plt.hist([mini, maxi], bins = channel_list, color = ['yellow', 'green'],\n",
    "    #            edgecolor = 'red', hatch = '/', label = ['Mini', 'Maxi'],\n",
    "    #            histtype = 'bar')\n",
    "    plt.ylabel('valeurs')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.title('2 series superposees')\n",
    "    plt.legend()\n",
    "    return channel_list,mini,maxi\n",
    "    \n",
    "\n",
    "    \n",
    "def studies(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "\n",
    "        #rolmean=ts.rolling(500).mean()\n",
    "        rolmean=ts.rolling(window=16).mean()\n",
    "        rolstd=ts.rolling(16).std()\n",
    "        print('Rolmean:====>',rolmean.dropna(inplace=False))\n",
    "        print('Rolstd:====>',rolstd.dropna(inplace=False))\n",
    "        \n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(rolstd.dropna(inplace=False), model='additive', freq=16)\n",
    "        result.plot()\n",
    "        \n",
    "        #2Plot rolling statistics\n",
    "        #orig=plt.plot(ts,color='blue',label='Original')\n",
    "        #print(ts)\n",
    "        mean=plt.plot(rolmean,color='red',label='Rolling Mean')\n",
    "        #std=plt.plot(rolstd,color='black',label='Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #plt.show(block=False)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "    \n",
    "def studies_autocorre(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "        plt.acorr(ts)\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('Lag')\n",
    "\n",
    "        plt.ylabel('Autocorrelation')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "def plot_acfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_acf(ts, lags=16)\n",
    "        #title1='Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_pacfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_pacf(ts, lags=16)\n",
    "        #title1='Partial Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Partial Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_seasonality(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(ts, model='additive', freq=16)\n",
    "        result.plot()\n",
    "        title1='Seasonality PDR '+str(src)+\"==>\"+str(dst)\n",
    "        #title1='Seasonality  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        \n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "\n",
    "        \n",
    "def general_time_series(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies(df,i,j)\n",
    "                \n",
    "def general_autocorre(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies_autocorre(df,i,j)\n",
    "                \n",
    "def general_acf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_acfi(df,i,j)\n",
    "            \n",
    "            \n",
    "def general_pacf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_pacfi(df,i,j)\n",
    "                \n",
    "def general_seasonality(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_seasonality(df,i,j)\n",
    "\n",
    "def puissant_arma(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    print(df)\n",
    "    #ts=df.loc[(df['channel']==11)]\n",
    "    ts=df['pdr']\n",
    "    \n",
    "    print(ts)\n",
    "    size=int(len(ts)*0.66)\n",
    "    train, test=ts[0:size],ts[size:len(ts)]\n",
    "    history=[x for x in train]\n",
    "    predictions=list()\n",
    "    \n",
    "    \n",
    "    for t in range(len(test)):\n",
    "        model=ARMA(history,order=(2,1))\n",
    "        model_fit=model.fit(disp=0)\n",
    "        output=model_fit.forecast()\n",
    "        yhat=output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs=test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted: ', yhat,' and expected= ',obs)\n",
    "    \n",
    "    #r21 = r2_score(test,predictions)\n",
    "    #mse1=mean_squared_error(test,predictions)\n",
    "    #rmse1 = np.sqrt(mse1) \n",
    "   \n",
    "    #print('R-Square is: ',r21,'\\n')\n",
    "    #print('MSE is: ',mse1,'\\n')\n",
    "    #print('RMSE is: ',rmse1) \n",
    "    \n",
    "    #plt.plot(test)\n",
    "    #ts['predictions']=predictions\n",
    "    #plt.plot(ts['predictions'],color='red')\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "def decision_tree_pdr(df,src,dst):\n",
    "    \n",
    "    from sklearn import tree\n",
    "    from sklearn.datasets import load_iris\n",
    "    #iris=load_iris()    \n",
    "    #print(iris)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "            target_names.append('Bad')\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "            target_names.append('Good')\n",
    "        else:\n",
    "            target.append(1)\n",
    "            target_names.append('Intermediate')\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    #df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    #print(df['target'].unique())\n",
    "    clf=tree.DecisionTreeClassifier(random_state=0)\n",
    "    colonne=['pdr','mean_rssi','target']\n",
    "    #test=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    test=df[['pdr','mean_rssi']]\n",
    "    clf=clf.fit(test.values,target)\n",
    "    \n",
    "    dot_data=tree.export_graphviz(clf,out_file=None,\n",
    "                                 feature_names=test.columns.values,\n",
    "                                 class_names=df.target_names.unique(),\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "    graph=graphviz.Source(dot_data)\n",
    "    graph.render('link1')\n",
    "    print('Initial: ',test.values)\n",
    "    print('The predicted class is: ',clf.predict(test.values))\n",
    "    print('The decision path is: ',clf.decision_path(test.values))\n",
    "    print('The score is: ',clf.score(test.values,target))\n",
    "    print('The probabilities of each class is: ',clf.predict_proba(test.values))\n",
    "    \n",
    "    #tree.plot_tree(clf.fit(test,df['target']))\n",
    "    \n",
    "    \n",
    "#Functions to plot the confusion matrix\n",
    "\n",
    "def trace_conf_mat(cm, acc,classes, norm, title,cmap=plt.cm.Blues):\n",
    "    accuracy=acc\n",
    "    if norm:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title+'%.4f' % accuracy,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.3f' if norm else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_confusion_matrix_pdr(df, classes, cm,accuracy, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    trace_conf_mat(cm, accuracy,classes, normalize, title,cmap=plt.cm.Blues)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "    \n",
    "#The \"my_split\" function aims to split the dataset of the link src===>dst considering the test size of \"size_of_test\",\n",
    "#That is, the training set size is \"1-test_of_size\" for our models. This function returns respectively:\n",
    "# - features: The features' list which correspond to pdr*pdr+mean_rssi*mean_rssi in the case of pdr+rssi splitter\n",
    "# - labels: Labels corresponding to the previous features\n",
    "# - classes: different classes contained in the link: Bad, Good or Intermediate\n",
    "# - train_features: The trainning set used by the model\n",
    "# - train_labels: The Labels corresponding to the previous training set\n",
    "# - test_features: The Test set used by the models to predict\n",
    "# - test_labels: The labels set corresponding to the previous test set\n",
    "\n",
    "def my_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] < 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>=0.3 and df['pdr'][i]<=0.75)and df['mean_rssi'][i]<-70):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] < 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] < -70 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>-40 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    ts=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    ts2=df.loc[(df['src']==src)&(df['dst']==dst),colonne2]\n",
    "    \n",
    "    features=ts.values\n",
    "    labels=ts2['target_names'];\n",
    "    classes=labels.unique()\n",
    "    if len(classes)>1:\n",
    "        features, labels=ros.fit_resample(features, labels)#The ressampling strategy\n",
    "        labels=pd.Series(labels)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=False)\n",
    "    \n",
    "    return features,labels, classes, train_features,train_labels,test_features,test_labels\n",
    "\n",
    "\n",
    "#Logistic regression Classification\n",
    "def my_logreg(df,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"LR\\\\Log_Reg_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg PDR+RSSI= \"\n",
    "            text=\"Classes of LogReg(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"LR\\\\Log_Reg_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg PDR= \"\n",
    "            text=\"Classes of LogReg(PDR): \"\n",
    "        else:\n",
    "            title=path+\"LR\\\\Log_Reg_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg RSSI= \"\n",
    "            text=\"Classes of LogReg(RSSI): \"\n",
    "        LogReg=LogisticRegression()\n",
    "        LogReg.fit(train_features,train_labels)\n",
    "        accuracy=LogReg.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        pred_labels=LogReg.predict(test_features)\n",
    "        cm=confusion_matrix(test_labels,pred_labels)\n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        #print(text,classes)\n",
    "    #else:\n",
    "        #print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        #print('Number of classes: ',nb_classes)\n",
    "        #print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#SVM Classification\n",
    "def my_svm(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        if kind==\"all\":\n",
    "            title=path+\"SVM\\\\SVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM PDR+RSSI= \"\n",
    "            text=\"Classes of SVM(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"SVM\\\\SVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM PDR= \"\n",
    "            text=\"Classes of SVM(PDR): \"\n",
    "        else:\n",
    "            title=path+\"SVM\\\\SVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM RSSI= \"\n",
    "            text=\"Classes of SVM(RSSI): \"\n",
    "        clf = SVC(random_state=0, tol=1e-5)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        pred_labels=clf.predict(test_features)\n",
    "        accuracy=clf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        #print(text,classes)\n",
    "    #else:\n",
    "        #print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        #print('Number of classes: ',nb_classes)\n",
    "        #print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#linear SVM Classification  \n",
    "def my_linear_svm(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"LSVM\\\\LSVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM PDR+RSSI= \"\n",
    "            text=\"Classes of LSVM(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"LSVM\\\\LSVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM PDR= \"\n",
    "            text=\"Classes of LSVM(PDR): \"\n",
    "        else:\n",
    "            title=path+\"LSVM\\\\LSVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM RSSI= \"\n",
    "            text=\"Classes of LSVM(RSSI): \"\n",
    "        clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        pred_labels=clf.predict(test_features)\n",
    "        accuracy=clf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        #print(text,classes)\n",
    "    #else:\n",
    "        #print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        #print('Number of classes: ',nb_classes)\n",
    "        #print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#Random Forest Classification    \n",
    "\n",
    "def my_random_forest(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"RF\\\\RF_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF PDR+RSSI= \"\n",
    "            text=\"Classes of RF(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"RF\\\\RF_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF PDR= \"\n",
    "            text=\"Classes of RF(PDR): \"\n",
    "        else:\n",
    "            title=path+\"RF\\\\RF_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF RSSI= \"\n",
    "            text=\"Classes of RF(RSSI): \"\n",
    "        rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "        rf.fit(train_features, train_labels)\n",
    "        pred_labels=rf.predict(test_features)\n",
    "        accuracy=rf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        #print(text,classes)\n",
    "    #else:\n",
    "        #print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        #print('Number of classes: ',nb_classes)\n",
    "        #print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "def executor(df,src, dst, size_of_test,model_list,path):\n",
    "    import os\n",
    "    file_name=path+\"results1.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a+\")\n",
    "        #file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    for i in model_list:\n",
    "        if i=='lr':\n",
    "            lg_all=my_logreg(df,src,dst,size_of_test,'all',path)\n",
    "            lg_pdr=my_logreg(df,src,dst,size_of_test,'pdr',path)\n",
    "            lg_rssi=my_logreg(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LogReg,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lg_all)+','+str(lg_pdr)+','+str(lg_rssi))\n",
    "        elif i=='lsvm':\n",
    "            lsvm_all=my_linear_svm(df,src,dst,size_of_test,'all',path)\n",
    "            lsvm_pdr=my_linear_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            lsvm_rssi=my_linear_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LSVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lsvm_all)+','+str(lsvm_pdr)+','+str(lsvm_rssi))\n",
    "        elif i=='svm':\n",
    "            svm_all=my_svm(df,src,dst,size_of_test,'all',path)\n",
    "            svm_pdr=my_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            svm_rssi=my_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'SVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(svm_all)+','+str(svm_pdr)+','+str(svm_rssi))\n",
    "        elif i=='rf':  \n",
    "            rf_all=my_random_forest(df,src,dst,size_of_test,'all',path)\n",
    "            rf_pdr=my_random_forest(df,src,dst,size_of_test,'pdr',path)\n",
    "            rf_rssi=my_random_forest(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'RF,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(rf_all)+','+str(rf_pdr)+','+str(rf_rssi))\n",
    "    file.close()\n",
    "        \n",
    "        \n",
    "#The following function aims to compute the accuracies of all the links in the network for all our methods\n",
    "def final_executor(df,size_of_test,my_execution_list,path):\n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            colonne=[\"pdr\"]\n",
    "            ts=df.loc[(df['src']==sender)&(df['dst']==receiver),colonne]\n",
    "            if len(ts)>0:\n",
    "                print(\"Starting link \",sender,\"===\",receiver)\n",
    "                executor(df,sender,receiver,size_of_test,my_execution_list,path)\n",
    "                print(\"Ending link \",sender,\"===\",receiver)\n",
    "\n",
    "                \n",
    "                \n",
    "#This function returns respectivelly:\n",
    "#   - A list containing the simulation results of all our models in the form of 4 dataframes:  logistic regression, linear svm\n",
    "# svm and random forest respectivelly\n",
    "#   - A list containing the number of items resulted from the simulation in the same order as previously\n",
    "#   - A list representing the number of values where PDR+RSSI > PDR for each models\n",
    "#   - A list representing the number of values where PDR+RSSI < PDR for each models\n",
    "#   - representing the number of values where PDR+RSSI == PDR for each models\n",
    "                \n",
    "def stats_studies(file):\n",
    "    df = pd.read_table(file,sep = ',',header = 0)\n",
    "    lr=df.loc[(df['model']=='LogReg')]\n",
    "    lsvm=df.loc[(df['model']=='LSVM')]\n",
    "    svm=df.loc[(df['model']=='SVM')]\n",
    "    rf=df.loc[(df['model']=='RF')]\n",
    "    table=list()\n",
    "    table.append(lr)\n",
    "    table.append(lsvm)\n",
    "    table.append(svm)\n",
    "    table.append(rf)\n",
    "\n",
    "    table1=list() #List representing the number of values by implemented model in the dataset \n",
    "    table1.append(len(lr))\n",
    "    table1.append(len(lsvm))\n",
    "    table1.append(len(svm))\n",
    "    table1.append(len(rf))\n",
    "           \n",
    "    test1=lr.loc[(lr['accuracy_with_pdr_and_rssi']>lr['accuracy_with_pdr'])]\n",
    "    test2=lsvm.loc[(lsvm['accuracy_with_pdr_and_rssi']>lsvm['accuracy_with_pdr'])]\n",
    "    test3=svm.loc[(svm['accuracy_with_pdr_and_rssi']>svm['accuracy_with_pdr'])]\n",
    "    test4=rf.loc[(rf['accuracy_with_pdr_and_rssi']>rf['accuracy_with_pdr'])]\n",
    "   \n",
    "    table2=list() #List representing the number of values where PDR+RSSI > PDR for each models\n",
    "    table2.append(len(test1))\n",
    "    table2.append(len(test2))\n",
    "    table2.append(len(test3))\n",
    "    table2.append(len(test4))\n",
    "    \n",
    "    test1=lr.loc[(lr['accuracy_with_pdr_and_rssi']<lr['accuracy_with_pdr'])]\n",
    "    test2=lsvm.loc[(lsvm['accuracy_with_pdr_and_rssi']<lsvm['accuracy_with_pdr'])]\n",
    "    test3=svm.loc[(svm['accuracy_with_pdr_and_rssi']<svm['accuracy_with_pdr'])]\n",
    "    test4=rf.loc[(rf['accuracy_with_pdr_and_rssi']<rf['accuracy_with_pdr'])]\n",
    "\n",
    "    table3=list() #List representing the number of values where PDR+RSSI < PDR for each models\n",
    "    table3.append(len(test1))\n",
    "    table3.append(len(test2))\n",
    "    table3.append(len(test3))\n",
    "    table3.append(len(test4))\n",
    "    \n",
    "    test1=lr.loc[(lr['accuracy_with_pdr_and_rssi']==lr['accuracy_with_pdr'])]\n",
    "    test2=lsvm.loc[(lsvm['accuracy_with_pdr_and_rssi']==lsvm['accuracy_with_pdr'])]\n",
    "    test3=svm.loc[(svm['accuracy_with_pdr_and_rssi']==svm['accuracy_with_pdr'])]\n",
    "    test4=rf.loc[(rf['accuracy_with_pdr_and_rssi']==rf['accuracy_with_pdr'])]\n",
    "    \n",
    "    table4=list() #List representing the number of values where PDR+RSSI == PDR for each models\n",
    "    table4.append(len(test1))\n",
    "    table4.append(len(test2))\n",
    "    table4.append(len(test3))\n",
    "    table4.append(len(test4))\n",
    "    return table,table1,table2,table3,table4\n",
    "    \n",
    "#print(stats_studies(\"results1.csv\"))\n",
    "#my_execution_list=['lr', 'lsvm','svm','rf']\n",
    "#Path to save the pictures, you will first need to create the directories LR, LSVM, RF and SVM in that directory\n",
    "#path=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\ALL\\\\\" \n",
    "#final_executor(df,0.25,my_execution_list,path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
