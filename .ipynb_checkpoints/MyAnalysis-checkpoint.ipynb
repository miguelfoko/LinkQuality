{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bad' 'Good']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:720: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of LogReg(PDR+RSSI):  ['Bad' 'Good']\n",
      "['Intermediate' 'Good' 'Bad']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:720: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of LogReg(PDR):  ['Intermediate' 'Good' 'Bad']\n",
      "['Bad']\n",
      "You don't have enought classes to use this prediction method\n",
      "Number of classes:  1\n",
      "Classes:  ['Bad']\n",
      "['Bad' 'Good']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:720: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of LSVM(PDR+RSSI):  ['Bad' 'Good']\n",
      "['Intermediate' 'Good' 'Bad']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:720: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of LSVM(PDR):  ['Intermediate' 'Good' 'Bad']\n",
      "['Bad']\n",
      "You don't have enought classes to use this prediction method\n",
      "Number of classes:  1\n",
      "Classes:  ['Bad']\n",
      "['Bad' 'Good']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of SVM(PDR+RSSI):  ['Bad' 'Good']\n",
      "['Intermediate' 'Good' 'Bad']\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:720: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\WSN-LINK\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:28: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "Classes of SVM(PDR):  ['Intermediate' 'Good' 'Bad']\n",
      "['Bad']\n",
      "You don't have enought classes to use this prediction method\n",
      "Number of classes:  1\n",
      "Classes:  ['Bad']\n",
      "['Bad' 'Good']\n",
      "Normalized confusion matrix\n",
      "Confusion matrix, without normalization\n",
      "Classes of RF(PDR+RSSI):  ['Bad' 'Good']\n",
      "['Intermediate' 'Good' 'Bad']\n",
      "Normalized confusion matrix\n",
      "Confusion matrix, without normalization\n",
      "Classes of RF(PDR):  ['Intermediate' 'Good' 'Bad']\n",
      "['Bad']\n",
      "You don't have enought classes to use this prediction method\n",
      "Number of classes:  1\n",
      "Classes:  ['Bad']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "#rcParams['figure.figsize']=5,4\n",
    "#sb.set_style('whitegrid')\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "class_names=['Bad','Intermediate','Good']\n",
    "#print(type(df))\n",
    "#print(df.shape)#Affiche le nombre de ligne et le nombre de colonne de mon fichier\n",
    "#test=df.head(15)#Affiche les premières lignes du fichier (les ( premières))\n",
    "#print(df.columns)#Affiche toutes les colonnes du fichier(leur nom)\n",
    "#print(df.dtypes)#Affiche les noms des colones et leurs types\n",
    "#print(df.info())#Affiche les informations complémentaires sur chacun des champs (nombre d'occurence, type, ...)\n",
    "#test=df['mean_rssi'].describe()#Affiche les éléments de la statistique descriptive de la colonne donnée \n",
    "#test=df['datetime'].sort_values()#Permet de trier les données sélectionnées\n",
    "#test=df.iloc[0:10,:]#Affiche les 10 première lignes de mon fichier\n",
    "#test=df.iloc[0:10,[0,3,4,5]]#Affiche les colonnes 0, 3, 4 ert 5 des 10 premières lignes de mes données\n",
    "#test=df.loc[df['src']==0,:]#Affiche uniquement les lignes où le src=0\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),:]//Affiche uniquement les lignes dont src=0 et channel=11\n",
    "#colonne=['datetime', 'src', 'dst', 'channel', 'mean_rssi', 'pdr']\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),colonne]#Affiche les ligne dont src=0 et channel=11. N'affiche que les colonnes mentionnées dans le tableau \"colonne\"\n",
    "#df.hist(column='mean_rssi')#Trace l'histogramme de la colonne \"mean_rssi\"\n",
    "#df['mean_rssi'].plot.kde()#Permet de tracer la courbe des densité sur mean_rssi\n",
    "#df.hist(column='mean_rssi',by='channel')#Trace l'histogramme de lean_rssi en fonction de channel\n",
    "#test = pd.date_range(start='1/1/2018', end='1/12/2018', freq='D')\n",
    "\n",
    "#df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')#Convertie les données de la colone 'datetime' en type date\n",
    "#df=df.set_index('datetime')\n",
    "#df.hist(column='mean_rssi',by='datetime')\n",
    "target_count=df.channel.value_counts()\n",
    "\n",
    "labels = df.columns[5]\n",
    "\n",
    "X = df[labels]\n",
    "y = df['pdr']\n",
    "\n",
    "def val_prediction_pdr(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.02:\n",
    "            ret.append(0.5)\n",
    "        elif df['pdr'][i] >= 0.02 and df['pdr'][i] < 0.25:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.25 and df['pdr'][i] < 0.3:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] >= 0.3 and df['pdr'][i] <= 0.35:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.35 and df['pdr'][i] <= 0.73:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.73 and df['pdr'][i] <= 0.75:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] > 0.75 and df['pdr'][i] <= 0.8:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.8 and df['pdr'][i] < 0.85:\n",
    "            ret.append(0.5)\n",
    "        else:\n",
    "            ret.append(df['pdr'][i])\n",
    "    #print(ret)\n",
    "    return ret\n",
    "\n",
    " \n",
    "\n",
    "def logistic_regression_init(df):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    target=list()\n",
    "    val_pred=val_prediction_pdr(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "        else:\n",
    "            target.append(1)\n",
    "        \n",
    "        if val_pred[i] < 0.3:\n",
    "            y_pred.append(0)\n",
    "        elif val_pred[i] > 0.75:\n",
    "            y_pred.append(2)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    df['target']=target\n",
    "    df['pred']=y_pred\n",
    "    y=df['pred']\n",
    "    mydata=df.ix[:,(5,7)].values\n",
    "    pdr=df['pdr']\n",
    "    target=df['target']\n",
    "    spearmanr_coefficient,p_value=spearmanr(pdr,target)\n",
    "    #print(' Spearmanr Rank Correlation %0.3f' %(spearmanr_coefficient))\n",
    "    X=scale(mydata)\n",
    "    LogReg=LogisticRegression()\n",
    "    LogReg.fit(X,y)\n",
    "    print (LogReg.score(X,y))\n",
    "    y_pred=LogReg.predict(X)\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y,y_pred))\n",
    "    \n",
    "\n",
    "def arma(df, classes, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    target=list()\n",
    "    val_pred=val_prediction_pdr(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "        else:\n",
    "            target.append(1)\n",
    "        \n",
    "        if val_pred[i] < 0.3:\n",
    "            y_pred.append(0)\n",
    "        elif val_pred[i] > 0.75:\n",
    "            y_pred.append(2)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    df['target']=target\n",
    "    df['pred']=y_pred\n",
    "    mydata=df.ix[:,(5,7)].values#Column 5 corresponds to the value of PDR and column 7 to the value representing that valu in class(BadnGood and Intermediate)\n",
    "    X=scale(mydata)\n",
    "    y=df['pred']\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    \n",
    "    my_y=df['target']\n",
    "    arma = ARMA(my_y,order=[4,4])\n",
    "    \n",
    "    res=arma.fit(trend=\"nc\")\n",
    "    params=res.params\n",
    "    residuals = res.resid\n",
    "    p = res.k_ar\n",
    "    q = res.k_ma\n",
    "    k_exog = res.k_exog\n",
    "    k_trend = res.k_trend\n",
    "    steps = 1\n",
    "    \n",
    "    y_pred=arma.predict(params)\n",
    "    \n",
    "    print('y_pred:  ==>', y_pred)\n",
    "    \n",
    "    print ('Accuracy ARMA: ',arma.score(y_pred))\n",
    "    #print (arma.predict(y))\n",
    "    #y_pred=arma.predict(X)\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "def plot_ar4(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(2,1,0))\n",
    "    results_AR=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_AR.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\AR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "        \n",
    "def plot_ma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(0,1,2))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\MA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "def plot_arima(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(1,0,1))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\ARIMA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_arma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df['pdr']\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    res=model.fit(disp=-1)\n",
    "    plt.plot(ts)\n",
    "    plt.plot(res.fittedvalues,color='red')\n",
    "    #plt.title('RSS: %.4f'% sum((res.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\ARMA1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    res= res.predict()\n",
    "\n",
    "    \n",
    "    #plt.ylabel('Baysian Information Criterion')\n",
    "    #plt.plot(res)\n",
    "    #plt.show()\n",
    "    print(\"According to Baysian Information criteria, we can use (ARMA(3,0) model)\")\n",
    "    print (\"min: \",ts.index.min())\n",
    "    print (\"max: \",ts.index.max())\n",
    "    \n",
    "def plot_test(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    df.index = df.index.to_period('H')\n",
    "    #dep = df[[\"channel\",\"pdr\"]].groupby(\"channel\", as_index=True).mean()\n",
    "    nb=df.index.unique()\n",
    "    print(\"Nb de date= \",len(nb))\n",
    "    ts=df['pdr']\n",
    "    print(ts)\n",
    "\n",
    "    \n",
    "def plot_test2(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df.loc[(df['channel']==11)]\n",
    "    ts=ts['pdr']\n",
    "    print(len(ts))\n",
    "    plt.plot(ts)\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    model_fit=model.fit(disp=0)\n",
    "    print(model_fit.summary())\n",
    "    plt.plot(ts)\n",
    "    pred=model_fit.forecast()\n",
    "    plt.plot(pred[0],color='blue')\n",
    "    plt.title('ARMA(1,1) On channel ',11,' With accuracy: ')\n",
    "    plt.savefig(\"ARMA\\ARMA_Chanel11_1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "\n",
    "def stationarity(ts,seuil):\n",
    "    tsa=np.exp(ts)\n",
    "    rolmean=tsa.rolling(window=1).mean()\n",
    "    rolstd=tsa.rolling(1).std()\n",
    "    \n",
    "    print('rolling_mean: ',rolmean)\n",
    "    #print('rolstd_mean: ',rolstd)\n",
    "    \n",
    "    ts1=ts-rolmean\n",
    "    ts1.dropna(inplace=True)\n",
    "    plt.plot(ts1,color='black')\n",
    "    \n",
    "    ts2=ts-rolstd\n",
    "    ts2.dropna(inplace=True)\n",
    "    plt.plot(ts2,color='yellow')\n",
    "    \n",
    "    plt.plot(ts,color='red')\n",
    "    results = adfuller(ts2, autolag='AIC')\n",
    "    print('ADF Statistic: ', results[0])\n",
    "    print('P-Value: ',results[1])\n",
    "    print('Critical values: ')\n",
    "    for key,value in results[4].items():\n",
    "        print('\\t ',key,': %.3f'%(value))\n",
    "\n",
    "        \n",
    "def channel_in_a_link(df,src,dst):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')\n",
    "    df=df.set_index('datetime')\n",
    "    color_list = [\"blue\", \"red\"]\n",
    "    \n",
    "    \n",
    "    ts=df.loc[(df['src']==src)&((df['dst']==dst))]\n",
    "    #ts=ts.loc[((ts['src']==src)&(ts['dst']==dst))|((ts['src']==dst)&(ts['dst']==src))]\n",
    "    #ts=ts.loc[(ts['src']==src)&(ts['dst']==dst)]\n",
    "    for link, df_link in ts.groupby([\"src\"]):\n",
    "        #dep = df_link[[\"channel\",\"pdr\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #dep = df_link[[\"channel\",\"mean_rssi\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #print(dep)\n",
    "        for ln,ln1 in df_link.groupby(\"channel\"):\n",
    "            #print(ln1)\n",
    "            plt.plot(ln1.index, 0.95*ln1.mean_rssi / 100 + ln,\n",
    "            #plt.plot(ln1.index, 0.8 * ln1.pdr + ln,\n",
    "                          '-', zorder=1, markersize=2,\n",
    "                          color=color_list[ln%len(color_list)])\n",
    "        #print(ln1.channel)\n",
    "        day1_start = pd.to_datetime(\"2018-01-11 22:00:00.000\")\n",
    "        day1_stop = pd.to_datetime(\"2018-01-12 06:00:00.000\")\n",
    "        plt.fill_between([day1_start, day1_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        day2_start = pd.to_datetime(\"2018-01-12 22:00:00.000\")\n",
    "        day2_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        plt.fill_between([day2_start, day2_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        #day3_start = pd.to_datetime(\"2018-01-13 20:00:00.000\")\n",
    "        #day3_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        #plt.fill_between([day3_start, day3_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        #plt.ylabel('PDR (%) per IEEE802.15.4 Channel')\n",
    "        plt.ylabel('Average RSSI (dBm) per IEEE802.15.4 Channel')\n",
    "        plt.ylim([10, 27])\n",
    "        plt.yticks(df.channel.unique())\n",
    "        #plt.xticks(df.index.unique())\n",
    "        plt.grid(True)\n",
    "        #xfmt = md.DateFormatter('%H:%M:%s')\n",
    "        #xfmt = md.DateFormatter('%M:%S')\n",
    "        xfmt = md.DateFormatter('%Y-%m-%d %H')\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(xfmt)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        #plt.savefig(\"time_pdr\\pdr_time_per_channel_{0}.png\".format(link), format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "def general_channel_in_link(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                channel_in_a_link(df,i,j)\n",
    "        \n",
    "def spaguetti_plot_pdr(df,channel):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    ts=df['pdr']\n",
    "    #ts=df['mean_rssi']\n",
    "    \n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    ts=df.loc[(df['channel']==channel)]\n",
    "    plt.plot(ts,color='red')\n",
    "    plt.ylim(0, 1)\n",
    "    #plt.ylim(-100, 0)\n",
    "\n",
    "    #plt.xlabel('PDR')\n",
    "    plt.xlabel('Time')\n",
    "    #plt.ylabel('MEAN RSSI')\n",
    "    plt.ylabel('PDR')\n",
    "    plt.title('PDR spaguetti plot by channel')\n",
    "    plt.grid(True)\n",
    "\n",
    "    #plt.show()\n",
    "    title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_spaguethiPlot.png\"\n",
    "    #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_spaguethiPlot.png\"\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.savefig(\"PDR_BY_RSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def min_max(df):\n",
    "    mini=list()\n",
    "    maxi=list()\n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    for i in channel_list:\n",
    "        ts=df.loc[(df['channel']==i)]\n",
    "        mini.append(min(ts['pdr'])*1)\n",
    "        maxi.append(max(ts['pdr'])*1)\n",
    "        \n",
    "    print('Mini:===>',mini)\n",
    "    print(\"Maxi:===>\",maxi)\n",
    "    print('channel_List:==>',channel_list)\n",
    "    plt.hist(mini)\n",
    "    #plt.hist([mini, maxi], bins = channel_list, color = ['yellow', 'green'],\n",
    "    #            edgecolor = 'red', hatch = '/', label = ['Mini', 'Maxi'],\n",
    "    #            histtype = 'bar')\n",
    "    plt.ylabel('valeurs')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.title('2 series superposees')\n",
    "    plt.legend()\n",
    "    return channel_list,mini,maxi\n",
    "    \n",
    "\n",
    "    \n",
    "def studies(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "\n",
    "        #rolmean=ts.rolling(500).mean()\n",
    "        rolmean=ts.rolling(window=16).mean()\n",
    "        rolstd=ts.rolling(16).std()\n",
    "        print('Rolmean:====>',rolmean.dropna(inplace=False))\n",
    "        print('Rolstd:====>',rolstd.dropna(inplace=False))\n",
    "        \n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(rolstd.dropna(inplace=False), model='additive', freq=16)\n",
    "        result.plot()\n",
    "        \n",
    "        #2Plot rolling statistics\n",
    "        #orig=plt.plot(ts,color='blue',label='Original')\n",
    "        #print(ts)\n",
    "        mean=plt.plot(rolmean,color='red',label='Rolling Mean')\n",
    "        #std=plt.plot(rolstd,color='black',label='Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #plt.show(block=False)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "    \n",
    "def studies_autocorre(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "        plt.acorr(ts)\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('Lag')\n",
    "\n",
    "        plt.ylabel('Autocorrelation')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "def plot_acfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_acf(ts, lags=16)\n",
    "        #title1='Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_pacfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_pacf(ts, lags=16)\n",
    "        #title1='Partial Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Partial Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_seasonality(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(ts, model='additive', freq=16)\n",
    "        result.plot()\n",
    "        title1='Seasonality PDR '+str(src)+\"==>\"+str(dst)\n",
    "        #title1='Seasonality  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        \n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "\n",
    "        \n",
    "def general_time_series(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies(df,i,j)\n",
    "                \n",
    "def general_autocorre(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies_autocorre(df,i,j)\n",
    "                \n",
    "def general_acf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_acfi(df,i,j)\n",
    "            \n",
    "            \n",
    "def general_pacf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_pacfi(df,i,j)\n",
    "                \n",
    "def general_seasonality(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_seasonality(df,i,j)\n",
    "\n",
    "def puissant_arma(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    print(df)\n",
    "    #ts=df.loc[(df['channel']==11)]\n",
    "    ts=df['pdr']\n",
    "    \n",
    "    print(ts)\n",
    "    size=int(len(ts)*0.66)\n",
    "    train, test=ts[0:size],ts[size:len(ts)]\n",
    "    history=[x for x in train]\n",
    "    predictions=list()\n",
    "    \n",
    "    \n",
    "    for t in range(len(test)):\n",
    "        model=ARMA(history,order=(2,1))\n",
    "        model_fit=model.fit(disp=0)\n",
    "        output=model_fit.forecast()\n",
    "        yhat=output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs=test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted: ', yhat,' and expected= ',obs)\n",
    "    \n",
    "    #r21 = r2_score(test,predictions)\n",
    "    #mse1=mean_squared_error(test,predictions)\n",
    "    #rmse1 = np.sqrt(mse1) \n",
    "   \n",
    "    #print('R-Square is: ',r21,'\\n')\n",
    "    #print('MSE is: ',mse1,'\\n')\n",
    "    #print('RMSE is: ',rmse1) \n",
    "    \n",
    "    #plt.plot(test)\n",
    "    #ts['predictions']=predictions\n",
    "    #plt.plot(ts['predictions'],color='red')\n",
    "    #plt.show()\n",
    "def val_prediction_pdr(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.02:\n",
    "            ret.append(0.5)\n",
    "        elif df['pdr'][i] >= 0.02 and df['pdr'][i] < 0.25:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.25 and df['pdr'][i] < 0.3:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] >= 0.3 and df['pdr'][i] <= 0.35:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.35 and df['pdr'][i] <= 0.73:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.73 and df['pdr'][i] <= 0.75:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] > 0.75 and df['pdr'][i] <= 0.8:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.8 and df['pdr'][i] < 0.85:\n",
    "            ret.append(0.5)\n",
    "        else:\n",
    "            ret.append(df['pdr'][i])\n",
    "    return ret\n",
    "\n",
    "def decision_tree_pdr(df,src,dst):\n",
    "    \n",
    "    from sklearn import tree\n",
    "    from sklearn.datasets import load_iris\n",
    "    #iris=load_iris()    \n",
    "    #print(iris)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "            target_names.append('Bad')\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "            target_names.append('Good')\n",
    "        else:\n",
    "            target.append(1)\n",
    "            target_names.append('Intermediate')\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    sample=val_prediction_pdr(df)\n",
    "    df['sample']=sample\n",
    "    #df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    #print(df['target'].unique())\n",
    "    clf=tree.DecisionTreeClassifier(random_state=0)\n",
    "    colonne=['pdr','mean_rssi','target']\n",
    "    #test=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    test=df[['pdr','mean_rssi']]\n",
    "    clf=clf.fit(test.values,target)\n",
    "    \n",
    "    dot_data=tree.export_graphviz(clf,out_file=None,\n",
    "                                 feature_names=test.columns.values,\n",
    "                                 class_names=df.target_names.unique(),\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "    graph=graphviz.Source(dot_data)\n",
    "    graph.render('link1')\n",
    "    print('Initial: ',test.values)\n",
    "    print('The predicted class is: ',clf.predict(test.values))\n",
    "    print('The decision path is: ',clf.decision_path(test.values))\n",
    "    print('The score is: ',clf.score(test.values,target))\n",
    "    print('The probabilities of each class is: ',clf.predict_proba(test.values))\n",
    "    \n",
    "    #tree.plot_tree(clf.fit(test,df['target']))\n",
    "    \n",
    "    \n",
    "def example(df):\n",
    "    from sklearn import tree\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.tree.export import export_text\n",
    "    iris=load_iris()    \n",
    "    clf=tree.DecisionTreeClassifier()\n",
    "    clf=clf.fit(iris.data,iris.target)\n",
    "    print(\"iris.feature_names==>\", iris.feature_names)\n",
    "    print(\"iris.target_names==>\",iris.target_names)\n",
    "    dot_data=tree.export_graphviz(clf,out_file=None,\n",
    "                                 feature_names=iris.feature_names,\n",
    "                                 class_names=iris.target_names,\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "    graph=graphviz.Source(dot_data)\n",
    "    graph.render('iris')\n",
    "    X=iris['data']\n",
    "    print('X==>',X)\n",
    "    y=iris['target']\n",
    "    print(y)\n",
    "    decision_tree=DecisionTreeClassifier(random_state=0,max_depth=2)\n",
    "    decision_tree=decision_tree.fit(X,y)\n",
    "    #r=export_text(decision_tree,feature_names=iris['feature_names'])\n",
    "    #print(r)\n",
    "    \n",
    "#Functions to plot the confusion matrix\n",
    "\n",
    "def trace_conf_mat(cm, acc,classes, norm, title,cmap=plt.cm.Blues):\n",
    "    accuracy=acc\n",
    "    \n",
    "    if norm:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title+'%.4f' % accuracy,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.3f' if norm else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_confusion_matrix_pdr(df, classes, cm,accuracy, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    trace_conf_mat(cm, accuracy,classes, normalize, title,cmap=plt.cm.Blues)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "    \n",
    "#The \"my_split\" function aims to split the dataset of the link src===>dst considering the test size of \"size_of_test\",\n",
    "#That is, the training set size is \"1-test_of_size\" for our models. This function returns respectively:\n",
    "# - features: The features' list which correspond to pdr*pdr+mean_rssi*mean_rssi in the case of pdr+rssi splitter\n",
    "# - labels: Labels corresponding to the previous features\n",
    "# - classes: different classes contained in the link: Bad, Good or Intermediate\n",
    "# - train_features: The trainning set used by the model\n",
    "# - train_labels: The Labels corresponding to the previous training set\n",
    "# - test_features: The Test set used by the models to predict\n",
    "# - test_labels: The labels set corresponding to the previous test set\n",
    "\n",
    "def my_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] < 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>=0.3 and df['pdr'][i]<=0.75)and df['mean_rssi'][i]<-70):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] < 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] < -70 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>-40 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Intermediate')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    ts=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    ts2=df.loc[(df['src']==src)&(df['dst']==dst),colonne2]\n",
    "    \n",
    "    features=ts.values\n",
    "    labels=ts2['target_names'];\n",
    "    classes=labels.unique()\n",
    "    print(classes)\n",
    "    if len(classes)>1:\n",
    "        features, labels=ros.fit_resample(features, labels)#The ressampling strategy\n",
    "        labels=pd.Series(labels)\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=False)\n",
    "    \n",
    "    return features,labels, classes, train_features,train_labels,test_features,test_labels\n",
    "\n",
    "\n",
    "#Logistic regression Classification\n",
    "def my_logreg(df,src,dst,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"LR\\\\Log_Reg_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg PDR+RSSI= \"\n",
    "            text=\"Classes of LogReg(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"LR\\\\Log_Reg_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg PDR= \"\n",
    "            text=\"Classes of LogReg(PDR): \"\n",
    "        else:\n",
    "            title=path+\"LR\\\\Log_Reg_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LR\\\\Log_Reg_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LogReg RSSI= \"\n",
    "            text=\"Classes of LogReg(RSSI): \"\n",
    "        LogReg=LogisticRegression()\n",
    "        LogReg.fit(train_features,train_labels)\n",
    "        accuracy=LogReg.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        pred_labels=LogReg.predict(test_features)\n",
    "        cm=confusion_matrix(test_labels,pred_labels)\n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        print(text,classes)\n",
    "    else:\n",
    "        print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        print('Number of classes: ',nb_classes)\n",
    "        print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#SVM Classification\n",
    "def my_svm(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        if kind==\"all\":\n",
    "            title=path+\"SVM\\\\SVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM PDR+RSSI= \"\n",
    "            text=\"Classes of SVM(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"SVM\\\\SVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM PDR= \"\n",
    "            text=\"Classes of SVM(PDR): \"\n",
    "        else:\n",
    "            title=path+\"SVM\\\\SVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"SVM\\\\SVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of SVM RSSI= \"\n",
    "            text=\"Classes of SVM(RSSI): \"\n",
    "        clf = SVC(random_state=0, tol=1e-5)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        pred_labels=clf.predict(test_features)\n",
    "        accuracy=clf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        print(text,classes)\n",
    "    else:\n",
    "        print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        print('Number of classes: ',nb_classes)\n",
    "        print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#linear SVM Classification  \n",
    "def my_linear_svm(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"LSVM\\\\LSVM_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM PDR+RSSI= \"\n",
    "            text=\"Classes of LSVM(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"LSVM\\\\LSVM_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM PDR= \"\n",
    "            text=\"Classes of LSVM(PDR): \"\n",
    "        else:\n",
    "            title=path+\"LSVM\\\\LSVM_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"LSVM\\\\LSVM_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of LSVM RSSI= \"\n",
    "            text=\"Classes of LSVM(RSSI): \"\n",
    "        clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "        clf.fit(train_features, train_labels)\n",
    "        pred_labels=clf.predict(test_features)\n",
    "        accuracy=clf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        print(text,classes)\n",
    "    else:\n",
    "        print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        print('Number of classes: ',nb_classes)\n",
    "        print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "#Random Forest Classification    \n",
    "\n",
    "def my_random_forest(df,src,dst,size_of_test,kind,path):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,src,dst,size_of_test,kind)\n",
    "    nb_classes= len(classes)\n",
    "    val_ret=-1\n",
    "    if nb_classes>1:\n",
    "        text=\"\"\n",
    "        if kind==\"all\":\n",
    "            title=path+\"RF\\\\RF_CM_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_ALL \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF PDR+RSSI= \"\n",
    "            text=\"Classes of RF(PDR+RSSI): \"\n",
    "        elif kind==\"pdr\":\n",
    "            title=path+\"RF\\\\RF_CM_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_PDR \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF PDR= \"\n",
    "            text=\"Classes of RF(PDR): \"\n",
    "        else:\n",
    "            title=path+\"RF\\\\RF_CM_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            title2=path+\"RF\\\\RF_CM_Not_Normalized_RSSI \"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "            subtitle=\"Accuracy of RF RSSI= \"\n",
    "            text=\"Classes of RF(RSSI): \"\n",
    "        rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "        rf.fit(train_features, train_labels)\n",
    "        pred_labels=rf.predict(test_features)\n",
    "        accuracy=rf.score(test_features,test_labels)\n",
    "        val_ret=accuracy\n",
    "        cm=confusion_matrix(test_labels,pred_labels)    \n",
    "\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "        plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "        plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        print(text,classes)\n",
    "    else:\n",
    "        print(\"You don\\'t have enought classes to use this prediction method\")\n",
    "        print('Number of classes: ',nb_classes)\n",
    "        print(\"Classes: \",classes)\n",
    "    return val_ret\n",
    "def executor(df,src, dst, size_of_test,model_list,path):\n",
    "    import os\n",
    "    file_name=path+\"results1.csv\"\n",
    "    exists=os.path.isfile(file_name)\n",
    "    if exists:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    else:\n",
    "        file=open(file_name,\"a\")\n",
    "        file.write(str('\\n')+'model,link,test_size,accuracy_with_pdr_and_rssi,accuracy_with_pdr,accuracy_with_rssi')\n",
    "    for i in model_list:\n",
    "        if i=='lr':\n",
    "            lg_all=my_logreg(df,src,dst,size_of_test,'all',path)\n",
    "            lg_pdr=my_logreg(df,src,dst,size_of_test,'pdr',path)\n",
    "            lg_rssi=my_logreg(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LogReg,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lg_all)+','+str(lg_pdr)+','+str(lg_rssi))\n",
    "        elif i=='lsvm':\n",
    "            lsvm_all=my_linear_svm(df,src,dst,size_of_test,'all',path)\n",
    "            lsvm_pdr=my_linear_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            lsvm_rssi=my_linear_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'LSVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(lsvm_all)+','+str(lsvm_pdr)+','+str(lsvm_rssi))\n",
    "        elif i=='svm':\n",
    "            svm_all=my_svm(df,src,dst,size_of_test,'all',path)\n",
    "            svm_pdr=my_svm(df,src,dst,size_of_test,'pdr',path)\n",
    "            svm_rssi=my_svm(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'SVM,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(svm_all)+','+str(svm_pdr)+','+str(svm_rssi))\n",
    "        elif i=='rf':  \n",
    "            rf_all=my_random_forest(df,src,dst,size_of_test,'all',path)\n",
    "            rf_pdr=my_random_forest(df,src,dst,size_of_test,'pdr',path)\n",
    "            rf_rssi=my_random_forest(df,src,dst,size_of_test,'rssi',path)\n",
    "            file.write(str('\\n')+'RF,'+str(src)+'==='+str(dst)+','+str(size_of_test)+','+str(rf_all)+','+str(rf_pdr)+','+str(rf_rssi))\n",
    "    file.close()\n",
    "        \n",
    "        \n",
    "#The following function aims to compute the accuracies of all the links in the network for all our methods\n",
    "def final_executor(df,size_of_test,my_execution_list,path):\n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            if sender!=receiver:\n",
    "                print(\"Starting link \",sender,\"===\",receiver)\n",
    "                executor(df,sender,receiver,size_of_test,my_execution_list,path)\n",
    "                print(\"Ending link \",sender,\"===\",receiver)\n",
    "        \n",
    "my_execution_list=['lr', 'lsvm','svm','rf']\n",
    "#Path to save the pictures, you will first need to create the directories LR, LSVM, RF and SVM in that directory\n",
    "path=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\ALL\\\\\" \n",
    "final_executor(df,size_of_test,my_execution_list,path)\n",
    "\n",
    "\n",
    "#my_random_forest(df,7,0,0.5,my_execution_list)     \n",
    "#my_linear_svm(df,7,0,0.5)   \n",
    "#my_svm(df,7,0,0.5)\n",
    "#my_logreg(df,7,0,0.5,\"all\")    \n",
    "#my_logreg(df,7,0,0.5,\"pdr\")    \n",
    "#my_logreg(df,7,0,0.5,\"rssi\")    \n",
    "#my_split(df,6,33,0.25)\n",
    "#tree.plot_tree(clf.fit(test,df['target']))\n",
    "#printer(df)    \n",
    "#example(df)    \n",
    "#decision_tree_pdr(df,0,20)   \n",
    "#plot_particular_seasonality(df,4,32,13)\n",
    "#general_seasonality(df)                \n",
    "#plot_seasonality(df,4,32)\n",
    "#test=df=df.loc[((df['src']==0)&(df['dst']==12))]              \n",
    "#print(test)\n",
    "#general_pacf(df)\n",
    "#general_acf(df)\n",
    "#studies(df,4,32)\n",
    "#plot_acfi(df,4,32)\n",
    "#plot_pacfi(df,4,32)\n",
    "#general_autocorre(df)\n",
    "#studies_autocorre(df,4,32)   \n",
    "#general_time_series(df)\n",
    "#min_max(df)\n",
    "#spaguetti_plot_pdr(df,11)    \n",
    "#channel_in_a_link(df,4,32)    \n",
    "#general_channel_in_link(df)\n",
    "#channel_in_a_link(df,1,14)\n",
    "#print(df)\n",
    "#puissant_arma(df,4,32)    \n",
    "#plot_test(df)    \n",
    "#plot_test2(df)    \n",
    "#plot_arma(df)\n",
    "#plot_ar4(df)\n",
    "#plot_ma(df)\n",
    "#plot_arima(df)   \n",
    "    #np.set_printoptions(precision=2)\n",
    "    \n",
    "#logistic_regression(df)\n",
    "#arma(df, classes=class_names, normalize=True,title='RF Accuracy of PDR without resampling= ')\n",
    "#plt.savefig(\"RF_CM_WithoutReampling.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "#linear_SVM(df, classes=class_names, normalize=True,title='SVM Accuracy of PDR= ') \n",
    "#plt.savefig(\"SVMConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
