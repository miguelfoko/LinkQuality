{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-86eb5bb3f78b>, line 978)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-86eb5bb3f78b>\"\u001b[1;36m, line \u001b[1;32m978\u001b[0m\n\u001b[1;33m    if len()\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.graphics.api as smg\n",
    "import matplotlib.dates as md\n",
    "import xgboost\n",
    "from sklearn import datasets, linear_model, svm\n",
    "from statsmodels.formula.api import ols\n",
    "from patsy.highlevel import dmatrices\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.stats import spearmanr\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 3,3\n",
    "import seaborn as sb\n",
    "from sklearn import metrics\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "\n",
    "class_names=['Bad','Intermediate','Good']\n",
    "\n",
    "\n",
    "correlations = df['mean_rssi'][0:].astype('float64').corr(df['pdr'][0:].astype('float64'))\n",
    "#print(correlations)\n",
    "\n",
    "#plt.matshow(df.corr())\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "def linear_regression_rssi_pdr():\n",
    "    y, X = dmatrices('mean_rssi ~ pdr', data=df, return_type='dataframe')\n",
    "    #print(X)\n",
    "    mod = sm.OLS(y, X)\n",
    "\n",
    "    res = mod.fit()\n",
    "    sm.stats.linear_rainbow(res)\n",
    "    sm.graphics.plot_fit(res, \"pdr\")\n",
    "\n",
    "    plt.savefig(\"Linear_Regression_RSSI_PDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "def correlation_rssi_pdr():\n",
    "    correlations = df['mean_rssi'][0:].astype('float64').corr(df['pdr'][0:].astype('float64'))\n",
    "    print(correlations)\n",
    "    y, X = dmatrices('mean_rssi ~ pdr', data=df, return_type='dataframe')\n",
    "\n",
    "    mod = sm.OLS(y, X)\n",
    "    model = mod.fit()\n",
    "\n",
    "    plt.plot(X,y, 'ro')\n",
    "    plt.plot(X, model.fittedvalues, 'b')\n",
    "    plt.ylim(-100,0)\n",
    "    plt.xlim(0,1)\n",
    "    #plt.hist(model.resid_pearson)\n",
    "\n",
    "    plt.xlabel('PDR (%)')\n",
    "    plt.ylabel('Average RSSI (in dBm)')\n",
    "    plt.title('Linear regression')\n",
    "\n",
    "    plt.savefig(\"Correlation_RSSI_PDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "def LinearRegression_rssi_pdr():\n",
    "    correlations = df['mean_rssi'][0:].astype('float64').corr(df['pdr'][0:].astype('float64'))\n",
    "    print(correlations)\n",
    "    y, X = dmatrices('mean_rssi ~ pdr', data=df, return_type='dataframe')\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99999, random_state=0, shuffle=False)\n",
    "    clf = LinearRegression(normalize=True)\n",
    "    clf.fit(X,y)\n",
    "    y_pred = clf.predict(X)\n",
    "    print(\"R2 Score===>: \",r2_score(y,y_pred))\n",
    "    \n",
    "def mean_pdr_per_channel():\n",
    "    dep = df[[\"channel\",\"pdr\"]].groupby(\"channel\", as_index=True).mean()\n",
    "    ax = dep.plot(kind = \"bar\", figsize=(10,5))\n",
    "    ax.set_xlabel(\"IEEE802.15.4 Channel\", fontsize=12)\n",
    "    ax.set_xlabel(\"PDR\", fontsize=12)\n",
    "    ax.set_title(\"PDR per channel\", fontsize=16)\n",
    "    ax.legend().set_visible(False)  # on supprime la légende\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig(\"Mean_PDR_PerChannel_Grenoble7.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "def mean_rssi_per_channel():\n",
    "    dep = df[[\"channel\",\"mean_rssi\"]].groupby(\"channel\", as_index=True).mean()\n",
    "    ax = dep.plot(kind = \"bar\", figsize=(10,5))\n",
    "    ax.set_xlabel(\"IEEE802.15.4 Channel\", fontsize=12)\n",
    "    ax.set_ylabel(\"Average RSSI\",fontsize=12)\n",
    "    ax.set_title(\"Average RSSI per channel\", fontsize=16)\n",
    "    ax.legend().set_visible(False)  # on supprime la légende\n",
    "    plt.ylim([-100, 0])\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.savefig(\"Mean_RSSI_PerChannel_Grenoble7.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "def pdr_time_per_channel(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')\n",
    "    df=df.set_index('datetime')\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    color_list = [\"blue\", \"red\"]\n",
    "    #for link, df_link in df.groupby([\"src\"]):\n",
    "    #df.groupby([\"src\"])\n",
    "    \n",
    "    for link, df_link in df.groupby([\"src\"]):\n",
    "        #dep = df_link[[\"channel\",\"pdr\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #dep = df_link[[\"channel\",\"mean_rssi\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #print(dep)\n",
    "        for ln,ln1 in df_link.groupby(\"channel\"):\n",
    "            #print(ln1)\n",
    "            plt.plot(ln1.index, 0.95*ln1.mean_rssi / 100 + ln,\n",
    "            #plt.plot(ln1.index, 0.95 * ln1.pdr + ln,\n",
    "                          '-', zorder=2, markersize=2,\n",
    "                          color=color_list[ln%len(color_list)])\n",
    "        #print(ln1.channel)\n",
    "        day1_start = pd.to_datetime(\"2018-01-11 22:00:00.000\")\n",
    "        day1_stop = pd.to_datetime(\"2018-01-12 06:00:00.000\")\n",
    "        plt.fill_between([day1_start, day1_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        day2_start = pd.to_datetime(\"2018-01-12 22:00:00.000\")\n",
    "        day2_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        plt.fill_between([day2_start, day2_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        #day3_start = pd.to_datetime(\"2018-01-13 20:00:00.000\")\n",
    "        #day3_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        #plt.fill_between([day3_start, day3_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        #plt.ylabel('PDR (%) per IEEE802.15.4 Channel')\n",
    "        plt.ylabel('Average RSSI (dBm) per IEEE802.15.4 Channel')\n",
    "        plt.ylim([10, 27])\n",
    "        plt.yticks(df.channel.unique())\n",
    "        #plt.xticks(df.index.unique())\n",
    "        plt.grid(True)\n",
    "        #xfmt = md.DateFormatter('%H:%M:%s')\n",
    "        #xfmt = md.DateFormatter('%M:%S')\n",
    "        xfmt = md.DateFormatter('%Y-%m-%d %H:%M:%S')\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(xfmt)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "\n",
    "        #plt.savefig(\"time_pdr\\pdr_time_per_channel_{0}.png\".format(link), format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig(\"rssi_time_per_channel_{0}.png\".format(link), format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "def rssi_or_pdr_per_channel(df):\n",
    "    df.hist(column='pdr',by='channel')\n",
    "    plt.savefig(\"pdr_per_channel.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    df.hist(column='mean_rssi',by='channel')\n",
    "    plt.savefig(\"rssi_per_channel.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "#Function to plot the confusion matrice\n",
    "\n",
    "def trace_conf_mat(cm, acc,classes, norm, title,cmap=plt.cm.Blues):\n",
    "    accuracy=acc\n",
    "    if norm:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title+'%.3f' % accuracy,\n",
    "           #ylabel='True label',\n",
    "           ylabel='Vrai label',\n",
    "           xlabel='Label prédit')\n",
    "    #plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "     #        rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.3f' if norm else '.0f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "#La fonction val_prediction à pour objectif de fournir une prédiction des valeurs en entrée. Cette prédiction aidera notamment dans la construction de la matrice de confusion\n",
    "\n",
    "def val_prediction_pdr(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.02:\n",
    "            ret.append(0.5)\n",
    "        elif df['pdr'][i] >= 0.02 and df['pdr'][i] < 0.25:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.25 and df['pdr'][i] < 0.3:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] >= 0.3 and df['pdr'][i] <= 0.35:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.35 and df['pdr'][i] <= 0.73:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.73 and df['pdr'][i] <= 0.75:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] > 0.75 and df['pdr'][i] <= 0.8:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.8 and df['pdr'][i] < 0.85:\n",
    "            ret.append(0.5)\n",
    "        else:\n",
    "            ret.append(df['pdr'][i])\n",
    "    return ret\n",
    "\n",
    "\n",
    "def conf_matrix_pdr(df):\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    val_pred=val_prediction_pdr(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            y_true.append('Bad')\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            y_true.append('Good')\n",
    "        else:\n",
    "            y_true.append('Intermediate')\n",
    "        \n",
    "        if val_pred[i] < 0.3:\n",
    "            y_pred.append('Bad')\n",
    "        elif val_pred[i] > 0.75:\n",
    "            y_pred.append('Good')\n",
    "        else:\n",
    "            y_pred.append('Intermediate')\n",
    "    #print (y_true)\n",
    "    #print(y_pred)\n",
    "    return confusion_matrix(y_true,y_pred)\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_pdr(df, classes, cm,accuracy, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "    trace_conf_mat(cm, accuracy,classes, normalize, title,cmap=plt.cm.Blues)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "def mse_rsquare(df):\n",
    "    d= val_prediction_pdr(df)\n",
    "    r2 = r2_score( df[\"pdr\"], d)\n",
    "    mse=mean_squared_error( df[\"pdr\"], d)\n",
    "    rmse = np.sqrt(mse)  \n",
    "    print('Values for PDR:\\n')\n",
    "    print('R-Square is: ',r2,'\\n')\n",
    "    print('MSE is: ',mse,'\\n')\n",
    "    print('RMSE is: ',rmse)    \n",
    "    \n",
    "    print('Values for AVERAGE RSSI:\\n')\n",
    "    \n",
    "    d1= val_prediction_rssi(df)\n",
    "    r21 = r2_score( df[\"mean_rssi\"], d1)\n",
    "    mse1=mean_squared_error( df[\"mean_rssi\"], d1)\n",
    "    rmse1 = np.sqrt(mse1)  \n",
    "   \n",
    "    print('R-Square is: ',r21,'\\n')\n",
    "    print('MSE is: ',mse1,'\\n')\n",
    "    print('RMSE is: ',rmse1)   \n",
    "    \n",
    "\n",
    "def val_prediction_rssi(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['mean_rssi'][i] < -89:\n",
    "            ret.append(-50)\n",
    "        elif df['mean_rssi'][i] >= -89 and df['mean_rssi'][i] <= -75:\n",
    "            ret.append(df['mean_rssi'][i])\n",
    "        elif df['mean_rssi'][i] > -75 and df['mean_rssi'][i] < -70:\n",
    "            ret.append(-30)\n",
    "        elif df['mean_rssi'][i] >= -70 and df['mean_rssi'][i] < -69:\n",
    "            ret.append(-75)\n",
    "        elif df['mean_rssi'][i] >= -69 and df['mean_rssi'][i] <= -42:\n",
    "             ret.append(df['mean_rssi'][i])\n",
    "        elif df['mean_rssi'][i] > -42 and df['mean_rssi'][i] <= -40:\n",
    "             ret.append(-30)\n",
    "        elif df['mean_rssi'][i] > -40 and df['mean_rssi'][i] <= -35:\n",
    "             ret.append(-75)\n",
    "        elif df['mean_rssi'][i] >=-30 and df['mean_rssi'][i] <= -26:\n",
    "             ret.append(df['mean_rssi'][i])\n",
    "        else:\n",
    "            ret.append(-50)\n",
    "    return ret\n",
    "\n",
    "def conf_matrix_rssi(df):\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    val_pred=val_prediction_rssi(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['mean_rssi'][i] < -70:\n",
    "            y_true.append('Bad')\n",
    "        elif df['mean_rssi'][i] > -40:\n",
    "            y_true.append('Good')\n",
    "        else:\n",
    "            y_true.append('Intermediate')\n",
    "        \n",
    "        if val_pred[i] < -70:\n",
    "            y_pred.append('Bad')\n",
    "        elif val_pred[i] > -40:\n",
    "            y_pred.append('Good')\n",
    "        else:\n",
    "            y_pred.append('Intermediate')\n",
    "    #print (y_true)\n",
    "    #print(y_pred)\n",
    "    conf=confusion_matrix(y_true,y_pred)\n",
    "    t=conf[0][0]+conf[1][1]+conf[2][2]\n",
    "    accuracy=t/len(df)\n",
    "    \n",
    "    #print('accuracy of average RSSI= ', accuracy)\n",
    "    return conf\n",
    "\n",
    "\n",
    "def trace_confusion_matrix():\n",
    "    plot_confusion_matrix_pdr(df, classes=class_names, title='Accuracy of PDR= ')\n",
    "    plt.savefig(\"ConfusionMatrixWithoutNormalizationPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plot_confusion_matrix_pdr(df, classes=class_names, normalize=True,title='Accuracy of PDR= ')\n",
    "    plt.savefig(\"NormalizedConfusionMatrixPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    plot_confusion_matrix_rssi(df, classes=class_names, title='Accuracy of Average RSSI= ')\n",
    "    plt.savefig(\"ConfusionMatrixWithoutNormalizationRSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plot_confusion_matrix_rssi(df, classes=class_names, normalize=True,title='Accuracy of Average RSSI= ')\n",
    "    plt.savefig(\"NormalizedConfusionMatrixRSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    logistic_regression(df, classes=class_names, title='LR Accuracy of PDR= ') \n",
    "    plt.savefig(\"LRConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    logistic_regression(df, classes=class_names, normalize=True,title='LR Accuracy of PDR= ')\n",
    "    plt.savefig(\"LRConfusionMatrixWithoutNormalizationPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    linear_SVM(df, classes=class_names, title='SVM Accuracy of PDR= ') \n",
    "    plt.savefig(\"SVMConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    linear_SVM(df, classes=class_names, normalize=True,title='SVM Accuracy of PDR= ')\n",
    "    plt.savefig(\"SVMConfusionMatrixWithoutNormalizationPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    random_forest(df, classes=class_names, title='RF Accuracy of PDR= ') \n",
    "    plt.savefig(\"RF_CM_WithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "   \n",
    "    random_forest(df, classes=class_names, normalize=True,title='RF Accuracy of PDR= ')\n",
    "    plt.savefig(\"RF_CM_WithoutNormalizationPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "def classes_plot(df):\n",
    "    target=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(\"Bad\")\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(\"Good\")\n",
    "        else:\n",
    "            target.append(\"Intermediate\")\n",
    "    df['target']=target\n",
    "    target_count=df.target.value_counts()\n",
    "    print('target_count: ', target_count)\n",
    "    target_count.plot(kind='bar', title='Count (PDR)', figsize=(10,6))\n",
    "    plt.ylim([0, 90000])\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"conf_mat\\Initial_bar_char.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "def ros_pdr(df):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    \n",
    "    target=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(\"Bad\")\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(\"Good\")\n",
    "        else:\n",
    "            target.append(\"Intermediate\")\n",
    "    df['target']=target\n",
    "    target_count=df.target.value_counts()\n",
    "    print('target_count: ', target_count)\n",
    "    \n",
    "    labels=df.columns[7:]\n",
    "    X=df[labels]\n",
    "    y=df['target']      \n",
    "            \n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    from collections import Counter\n",
    "    #print(sorted(Counter(y_resampled).items()))\n",
    "    bad=0\n",
    "    intermediate=0\n",
    "    good=0\n",
    "    for i in range(len(y_resampled)):\n",
    "        if y_resampled[i]== 'Bad':\n",
    "            bad=bad+1\n",
    "        elif y_resampled[i]== 'Intermediate':\n",
    "            intermediate=intermediate+1\n",
    "        else:\n",
    "            good=good+1\n",
    "    \n",
    "    df=pd.DataFrame({'Classes':['Bad','Good','Intermediate'],'Random Over Sampling (ROS) of PDR':[bad,good,intermediate]})\n",
    "    ax = df.plot.bar(x='Classes', y='Random Over Sampling (ROS) of PDR', figsize=(10,5))\n",
    "    ax.set_xlabel(\"Classes\", fontsize=12)\n",
    "    ax.set_title(\"Random Over Sampling (ROS) of PDR\", fontsize=16)\n",
    "    ax.legend().set_visible(False)\n",
    "    plt.ylim([0, 90000])\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"conf_mat\\ROS_bar_char.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "\n",
    "def rus_pdr(df):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    \n",
    "    target=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(\"Bad\")\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(\"Good\")\n",
    "        else:\n",
    "            target.append(\"Intermediate\")\n",
    "    df['target']=target\n",
    "    target_count=df.target.value_counts()\n",
    "    print('target_count: ', target_count)\n",
    "    \n",
    "    labels=df.columns[7:]\n",
    "    X=df[labels]\n",
    "    y=df['target']      \n",
    "    print('X:  =====================>: ',X)        \n",
    "    print('X:  =====================>: ',y)  \n",
    "    from collections import Counter\n",
    "    \n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    print(sorted(Counter(y_resampled).items()))\n",
    "    #print(y_resampled)\n",
    "    bad=0\n",
    "    intermediate=0\n",
    "    good=0\n",
    "    for i in range(len(y_resampled)):\n",
    "        if y_resampled[i]== 'Bad':\n",
    "            bad=bad+1\n",
    "        elif y_resampled[i]== 'Intermediate':\n",
    "            intermediate=intermediate+1\n",
    "        else:\n",
    "            good=good+1\n",
    "    \n",
    "    df=pd.DataFrame({'Classes':['Bad','Good','Intermediate'],'Random Under Sampling (RUS) of PDR':[bad,good,intermediate]})\n",
    "    ax = df.plot.bar(x='Classes', y='Random Under Sampling (RUS) of PDR', figsize=(10,5))\n",
    "    ax.set_xlabel(\"Classes\", fontsize=12)\n",
    "    ax.set_title(\"Random Under Sampling (RUS) of PDR\", fontsize=16)\n",
    "    ax.legend().set_visible(False)\n",
    "    plt.ylim([0, 90000])\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"conf_mat\\RUS_bar_char.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "   \n",
    "    \n",
    "def run_rus_ros_pdr(df):\n",
    "    rus_pdr(df)\n",
    "    ros_pdr(df)\n",
    "\n",
    "\n",
    "#Function returning the split over all the dataset\n",
    "def my_split(df,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] <= 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>0.3 and df['pdr'][i]<0.75)and df['mean_rssi'][i]<=-87):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] <= 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] <= -87 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>=-85 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    \n",
    "    features=df[colonne].values\n",
    "    labels=df[colonne2];\n",
    "    classes=df['target_names'].unique()\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=False)\n",
    "    \n",
    "    return features,labels, classes, train_features,train_labels,test_features,test_labels\n",
    "\n",
    "\n",
    "\n",
    "def linear_SVM(df, size_of_test,kind,path, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,size_of_test,kind)\n",
    "           \n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LSVM_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    pred_labels = clf.predict(test_features)\n",
    "\n",
    "    #Plotting of Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "    accuracy=clf.score(test_features,test_labels)\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "np.set_printoptions(precision=2)    \n",
    "\n",
    "def my_SVM(df, size_of_test,kind,path, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,size_of_test,kind)\n",
    "           \n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\SVM_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "    clf = SVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    pred_labels = clf.predict(test_features)\n",
    "\n",
    "    #Plotting of Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "    accuracy=clf.score(test_features,test_labels)\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "np.set_printoptions(precision=2)    \n",
    "\n",
    "    \n",
    "def logistic_regression(df, size_of_test,kind,path, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,size_of_test,kind)\n",
    "           \n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    pred_labels = clf.predict(test_features)\n",
    "\n",
    "    #Plotting of Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "    accuracy=clf.score(test_features,test_labels)\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "def random_forest(df, size_of_test,kind,path, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    features,labels, classes, train_features,train_labels,test_features,test_labels=my_split(df,size_of_test,kind)\n",
    "           \n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL_Not_Normalized.png\"\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR_Not_Normalized.png\"\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI_Not_Normalized.png\"\n",
    "        \n",
    "    clf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "    clf.fit(train_features, train_labels)\n",
    "    \n",
    "    pred_labels = clf.predict(test_features)\n",
    "\n",
    "    #Plotting of Confusion Matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(test_labels, pred_labels)\n",
    "    accuracy=clf.score(test_features,test_labels)\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    return accuracy\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "def executor(df,size_of_test,path,my_execution_list):\n",
    "    for i in range(len(my_execution_list)):\n",
    "        linear_SVM(df,size_of_test,my_execution_list[i],path)\n",
    "\n",
    "def rssi_by_pdr(rssi,pdr):\n",
    "    import statistics\n",
    "    rcParams['figure.figsize'] = 6,5\n",
    "    yi=[]\n",
    "    xi=[]\n",
    "    test=df.loc[df['pdr']==0.3,:]\n",
    "    test1=test[rssi]\n",
    "    test1=test1.values.tolist()\n",
    "    test2=test[pdr]\n",
    "    test2=test2.values.tolist()\n",
    "    for i in range(len(test1)):\n",
    "        yi.append(0.3)\n",
    "        #yi.append(test2[i])\n",
    "        xi.append(test1[i])\n",
    "    \n",
    "    yi1=[]\n",
    "    xi1=[]\n",
    "    test3=df.loc[(df['pdr']==0.75) ,:]\n",
    "    test4=test3[rssi]\n",
    "    test4=test4.values.tolist()\n",
    "    test5=test3[pdr]\n",
    "    test5=test5.values.tolist()\n",
    "    for i in range(len(test4)):\n",
    "        yi1.append(0.75)\n",
    "        #yi1.append(test5[i])\n",
    "        xi1.append(test4[i])\n",
    "        \n",
    "\n",
    "    median1=statistics.median(test1)\n",
    "    print(\"Médiane:==>\", statistics.median(test1))\n",
    "    \n",
    "    yi2=[]\n",
    "    xi2=[]\n",
    "    test6=df.loc[(df['mean_rssi']==median1)&(df['pdr']==0.3),:]\n",
    "    test7=test6[rssi]\n",
    "    test7=test7.values.tolist()\n",
    "    test8=test6[pdr]\n",
    "    test8=test8.values.tolist()\n",
    "    for i in range(len(test7)):\n",
    "        yi2.append(test8[i])\n",
    "        xi2.append(median1)\n",
    "        #xi2.append(test7[i])\n",
    "        \n",
    "        \n",
    "    median2=statistics.median(test4)\n",
    "    median2=round(median2,2)\n",
    "    print(\"Médiane :==>\", median2)\n",
    "    \n",
    "    yi3=[]\n",
    "    xi3=[]\n",
    "    test9=df.loc[(df['mean_rssi']==median2)&(df['pdr']==0.75),:]\n",
    "    test10=test9[rssi]\n",
    "    test10=test10.values.tolist()\n",
    "    test11=test9[pdr]\n",
    "    test11=test11.values.tolist() \n",
    "    for i in range(len(test10)):\n",
    "        yi3.append(test11[i])\n",
    "        xi3.append(median2)\n",
    "        #xi3.append(test10[i])\n",
    "        \n",
    "    \n",
    "    plt.scatter(df['mean_rssi'], df['pdr'],marker='+')\n",
    "    plt.scatter(xi,yi,marker='+',color='red',label = \"PDR = 0.3\")\n",
    "    #val=\"PDR =0.3 and RSSI == -87 \"\n",
    "    #plt.scatter(xi2,yi2,marker='+',color='cyan',label = val)\n",
    "    plt.scatter(xi1,yi1,marker='+',color='green',label = \"PDR = 0.75\")\n",
    "    #val2=\"PDR =0.75 and RSSI == -85\"\n",
    "    #plt.scatter(xi3,yi3,marker='+',color='black',label = val2)\n",
    "    plt.xlim(-100, 0)  # decreasing time\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "   \n",
    "    plt.xlabel('RSSI')\n",
    "   \n",
    "    plt.ylabel('PDR')\n",
    "    #plt.title('Evolution of RSSI over PDR')\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc = 'lower right') \n",
    "\n",
    "    #plt.show()\n",
    "    plt.savefig(\"RSSI_BY_PDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.savefig(\"PDR_BY_RSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def my_particular_split(df,src,dst,size_of_test,kind):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    \n",
    "    if kind==\"all\":                                              #it is for pdr+rssi\n",
    "        combined_features=list()\n",
    "        for i in range(len(df)):\n",
    "            combined_features.append(df['pdr'][i]*df['pdr'][i]+df['mean_rssi'][i]*df['mean_rssi'][i])\n",
    "            if df['pdr'][i] <= 0.3:\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75:\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            elif ((df['pdr'][i]>0.3 and df['pdr'][i]<0.75)and df['mean_rssi'][i]<=-87):\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "\n",
    "        df['combined_features']=combined_features\n",
    "        colonne=['combined_features']\n",
    "    elif kind==\"pdr\":                                            #It is for pdr\n",
    "        for i in range(len(df)):\n",
    "            if df['pdr'][i] <= 0.3 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['pdr'][i]>=0.75 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "            colonne=['pdr']\n",
    "    else:                                                          #It is for mean_rssi\n",
    "        for i in range(len(df)):\n",
    "            if df['mean_rssi'][i] <= -87 :\n",
    "                target.append(0)\n",
    "                target_names.append('Bad')\n",
    "            elif df['mean_rssi'][i]>=-85 :\n",
    "                target.append(2)\n",
    "                target_names.append('Good')\n",
    "            else:\n",
    "                target.append(1)\n",
    "                target_names.append('Interm.')\n",
    "        colonne=['mean_rssi']\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    colonne2=['target_names']\n",
    "    df=df.loc[(df['src']==src)&(df['dst']==dst)]\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def my_general_logreg(df,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    text=\"\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_ALL_Not_Normalized.png\"\n",
    "        colonne=['combined_features']\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_PDR_Not_Normalized.png\"\n",
    "        colonne=['pdr']\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\FINAL\\\\GENERAL\\\\LR_CM_RSSI_Not_Normalized.png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "        \n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()  \n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            ts=my_particular_split(df,sender,receiver,size_of_test,kind)\n",
    "            if len(ts)>0:\n",
    "                channel_list=ts['channel'].unique()\n",
    "                classes=ts['target_names'].unique()\n",
    "                for i in range (len(channel_list)):\n",
    "                    channel_i=channel_list[i]\n",
    "                    colonne2=['target_names']\n",
    "                    ts1=ts.loc[(ts['channel']==channel_i),colonne]\n",
    "                    ts2=ts.loc[(ts['channel']==channel_i),colonne2]\n",
    "\n",
    "                    features=ts1.values\n",
    "                    labels=ts2['target_names']\n",
    "                    #classes=labels.unique()\n",
    "                    #if len(classes)>1:\n",
    "                     #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "                     #   labels=pd.Series(labels)\n",
    "                    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "                    taill=len(pd.Series(train_labels).unique())\n",
    "                    if taill>1:\n",
    "                        LogReg=LogisticRegression()\n",
    "                        LogReg.fit(train_features,train_labels)\n",
    "                        pred_labels=LogReg.predict(test_features)\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "                    else:\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(test_labels)\n",
    "    \n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "def my_general_random_forest(df,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    text=\"\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL.png\"\n",
    "        title2=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_ALL_Not_Normalized.png\"\n",
    "        colonne=['combined_features']\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR.png\"\n",
    "        title2=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_PDR_Not_Normalized.png\"\n",
    "        colonne=['pdr']\n",
    "        \n",
    "    else:\n",
    "        title=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI.png\"\n",
    "        title2=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI_Not_Normalized.png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "        \n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()  \n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            print('Starting link: ',sender,'==>',receiver)\n",
    "            ts=my_particular_split(df,sender,receiver,size_of_test,kind)\n",
    "            if len(ts)>0:\n",
    "                channel_list=ts['channel'].unique()\n",
    "                classes=ts['target_names'].unique()\n",
    "                for i in range (len(channel_list)):\n",
    "                    channel_i=channel_list[i]\n",
    "                    colonne2=['target_names']\n",
    "                    ts1=ts.loc[(ts['channel']==channel_i),colonne]\n",
    "                    ts2=ts.loc[(ts['channel']==channel_i),colonne2]\n",
    "\n",
    "                    features=ts1.values\n",
    "                    labels=ts2['target_names']\n",
    "                    #classes=labels.unique()\n",
    "                    #if len(classes)>1:\n",
    "                     #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "                     #   labels=pd.Series(labels)\n",
    "                    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "                    taill=len(pd.Series(train_labels).unique())\n",
    "                    if taill>1:\n",
    "                        rf = RandomForestClassifier(n_estimators=1000, max_depth=5, random_state=0)\n",
    "                        rf.fit(train_features, train_labels)\n",
    "                        pred_labels=rf.predict(test_features)\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "                    else:\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(test_labels)\n",
    "            print('ending link: ',sender,'==>',receiver)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "def my_general_linear_svm(df,size_of_test,kind,path):#Kind can be \"pdr\", \"mean_rssi\" or \"all\"\n",
    "    text=\"\"\n",
    "    subtitle=\"Accuracy = \"\n",
    "    if kind==\"all\":\n",
    "        title=path+\"\\\\LSVM_CM_ALL.png\"\n",
    "        title2=path+\"\\\\LSVM_CM_ALL_Not_Normalized.png\"\n",
    "        colonne=['combined_features']\n",
    "        \n",
    "    elif kind==\"pdr\":\n",
    "        title=path+\"\\\\LSVM_CM_PDR.png\"\n",
    "        title2=path+\"\\\\LSVM_CM_PDR_Not_Normalized.png\"\n",
    "        colonne=['pdr']\n",
    "        \n",
    "    else:\n",
    "        title=path+\"\\\\LSVM_CM_RSSI.png\"\n",
    "        title2=path+\"\\\\LSVM_CM_RSSI_Not_Normalized.png\"\n",
    "        colonne=['mean_rssi']\n",
    "\n",
    "        \n",
    "    general_test_labels=list()\n",
    "    general_pred_labels=list()  \n",
    "    senders=df['src'].unique()\n",
    "    receivers=df['dst'].unique()\n",
    "    \n",
    "    for sender in senders:\n",
    "        for receiver in receivers:\n",
    "            print('starting link: ',sender,'==>',receiver)\n",
    "            ts=my_particular_split(df,sender,receiver,size_of_test,kind)\n",
    "            if len(ts)>0:\n",
    "                channel_list=ts['channel'].unique()\n",
    "                classes=ts['target_names'].unique()\n",
    "                for i in range (len(channel_list)):\n",
    "                    channel_i=channel_list[i]\n",
    "                    colonne2=['target_names']\n",
    "                    ts1=ts.loc[(ts['channel']==channel_i),colonne]\n",
    "                    ts2=ts.loc[(ts['channel']==channel_i),colonne2]\n",
    "\n",
    "                    features=ts1.values\n",
    "                    labels=ts2['target_names']\n",
    "                    #classes=labels.unique()\n",
    "                    #if len(classes)>1:\n",
    "                     #   features, labels=rus.fit_resample(features, labels)#The ressampling strategy\n",
    "                     #   labels=pd.Series(labels)\n",
    "                    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = size_of_test, random_state=None,shuffle=True)\n",
    "                    taill=len(pd.Series(train_labels).unique())\n",
    "                    if taill>1:\n",
    "                        lsvm = LinearSVC(random_state=0, tol=1e-5)\n",
    "                        lsvm.fit(train_features, train_labels)\n",
    "                        pred_labels=lsvm.predict(test_features)\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(pred_labels)\n",
    "                    else:\n",
    "                        general_test_labels=general_test_labels+list(test_labels)\n",
    "                        general_pred_labels=general_pred_labels+list(test_labels)\n",
    "            print('ending link: ',sender,'==>',receiver)\n",
    "    cm=confusion_matrix(general_test_labels,general_pred_labels)\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=subtitle)\n",
    "    \n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=subtitle)\n",
    "    plt.savefig(title2, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    return accuracy\n",
    "\n",
    "def draw_cm():\n",
    "    #cm=[[16,6],[0,43]]\n",
    "    cm=[[2818,0,68],[0,20673,30],[29,9,5299]]\n",
    "    cm=np.array(cm,dtype=np.float32)\n",
    "    #classes=['Interm.','Mauv.']\n",
    "    #classes=['Bon','Interm.','Mauv.']\n",
    "    classes=['Bon','Mauv.','Interm.']\n",
    "    #classes=['Interm.','Mauv.','Bon']\n",
    "    #classes=['Good','Bad','Interm.']\n",
    "    som=0\n",
    "    taill=len(cm)\n",
    "    total=0\n",
    "    for i in range(taill):\n",
    "        som=som+cm[i][i]\n",
    "        for j in range(taill):\n",
    "            total=total+cm[i][j]\n",
    "        \n",
    "    accuracy=som/total\n",
    "    \n",
    "    #plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=\"Accuracy = \")\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=True,title=\"Précision = \")\n",
    "    title=\"C:\\\\Users\\\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI.png\"\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    #(df, classes,cm,accuracy, normalize=False,title=\"Accuracy = \")\n",
    "    plot_confusion_matrix_pdr(df, classes,cm,accuracy, normalize=False,title=\"Précision = \")\n",
    "    title=\"C:\\\\Users\\\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\RF_CM_RSSI_Not_Normalized.png\"\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#from test1 import my_general_random_forest_with_threads as my_general_rf\n",
    "\n",
    "#logistic_regression(df, classes=class_names, title='LR Accuracy of PDR= ') \n",
    "#plt.savefig(\"PDR\\\\1LRConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "#logistic_regression(df, classes=class_names, normalize=True,title='LR Accuracy of PDR= ')\n",
    "#plt.savefig(\"LRConfusionMatrixNormalizedPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "path=\"C:\\\\Users\\Hp\\\\Documents\\\\TEST\\\\FINAL\\\\GENERAL\\\\\"\n",
    "\n",
    "#my_execution_list1=['all','pdr','rssi']\n",
    "#draw_cm()\n",
    "#my_general_logreg(df,0.25,'pdr',path)\n",
    "#my_general_random_forest(df,0.25,'all',path)\n",
    "my_general_linear_svm(df,0.25,'all',path)\n",
    "\n",
    "#executor(df,0.25,my_execution_list1,path)\n",
    "#logistic_regression(df,0.25,'all',path)\n",
    "#logistic_regression(df,0.25,'pdr',path)\n",
    "#logistic_regression(df,0.25,'rssi',path)\n",
    "    \n",
    "#linear_SVM(df, classes=class_names, title='SVM Accuracy of PDR= ') \n",
    "#plt.savefig(\"SVMConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "#linear_SVM(df, classes=class_names, normalize=True,title='SVM Accuracy of PDR= ')\n",
    "#plt.savefig(\"SVMConfusionMatrixWithoutNormalizationPDR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "#LinearRegression_rssi_pdr()\n",
    "#linear_SVM(df)    \n",
    "#rus_pdr(df)    \n",
    "#test(df)  \n",
    "#run_rus_ros_pdr(df)\n",
    "#classes_plot(df)    \n",
    "#trace_confusion_matrix()\n",
    "#print(conf_matrix_pdr(df))\n",
    "#print(conf_matrix_rssi(df))\n",
    "#print(val_prediction_pdr(df))    \n",
    "#test(df)\n",
    "#mse_rsquare(df)\n",
    "#mean_rssi_per_channel()    \n",
    "#rssi_or_pdr_per_channel(df)\n",
    "\n",
    "#pdr_time_per_channel(df)    \n",
    "#mean_pdr_per_channel()    \n",
    "#correlation_rssi_pdr()    \n",
    "#rssi_by_pdr(\"mean_rssi\",\"pdr\")    \n",
    "#linear_regression_rssi_pdr()\n",
    "#mat= numpy.corrcoef(df['mean_rssi'],df['pdr'])\n",
    "#print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
