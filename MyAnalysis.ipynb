{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_rows=10\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import xgboost\n",
    "import graphviz\n",
    "import matplotlib.dates as md\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy\n",
    "from scipy.stats import spearmanr\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.stattools import adfuller, arma_order_select_ic\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "#rcParams['figure.figsize']=5,4\n",
    "#sb.set_style('whitegrid')\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_table(\"grenoble_7.k7\",sep = ',',header = 0)\n",
    "class_names=['Bad','Intermediate','Good']\n",
    "#print(type(df))\n",
    "#print(df.shape)#Affiche le nombre de ligne et le nombre de colonne de mon fichier\n",
    "#test=df.head(15)#Affiche les premières lignes du fichier (les ( premières))\n",
    "#print(df.columns)#Affiche toutes les colonnes du fichier(leur nom)\n",
    "#print(df.dtypes)#Affiche les noms des colones et leurs types\n",
    "#print(df.info())#Affiche les informations complémentaires sur chacun des champs (nombre d'occurence, type, ...)\n",
    "#test=df['mean_rssi'].describe()#Affiche les éléments de la statistique descriptive de la colonne donnée \n",
    "#test=df['datetime'].sort_values()#Permet de trier les données sélectionnées\n",
    "#test=df.iloc[0:10,:]#Affiche les 10 première lignes de mon fichier\n",
    "#test=df.iloc[0:10,[0,3,4,5]]#Affiche les colonnes 0, 3, 4 ert 5 des 10 premières lignes de mes données\n",
    "#test=df.loc[df['src']==0,:]#Affiche uniquement les lignes où le src=0\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),:]//Affiche uniquement les lignes dont src=0 et channel=11\n",
    "#colonne=['datetime', 'src', 'dst', 'channel', 'mean_rssi', 'pdr']\n",
    "#test=df.loc[(df['src']==0)&(df['channel']==11),colonne]#Affiche les ligne dont src=0 et channel=11. N'affiche que les colonnes mentionnées dans le tableau \"colonne\"\n",
    "#df.hist(column='mean_rssi')#Trace l'histogramme de la colonne \"mean_rssi\"\n",
    "#df['mean_rssi'].plot.kde()#Permet de tracer la courbe des densité sur mean_rssi\n",
    "#df.hist(column='mean_rssi',by='channel')#Trace l'histogramme de lean_rssi en fonction de channel\n",
    "#test = pd.date_range(start='1/1/2018', end='1/12/2018', freq='D')\n",
    "\n",
    "#df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')#Convertie les données de la colone 'datetime' en type date\n",
    "#df=df.set_index('datetime')\n",
    "#df.hist(column='mean_rssi',by='datetime')\n",
    "target_count=df.channel.value_counts()\n",
    "\n",
    "labels = df.columns[5]\n",
    "\n",
    "X = df[labels]\n",
    "y = df['pdr']\n",
    "\n",
    "def val_prediction_pdr(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.02:\n",
    "            ret.append(0.5)\n",
    "        elif df['pdr'][i] >= 0.02 and df['pdr'][i] < 0.25:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.25 and df['pdr'][i] < 0.3:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] >= 0.3 and df['pdr'][i] <= 0.35:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.35 and df['pdr'][i] <= 0.73:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.73 and df['pdr'][i] <= 0.75:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] > 0.75 and df['pdr'][i] <= 0.8:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.8 and df['pdr'][i] < 0.85:\n",
    "            ret.append(0.5)\n",
    "        else:\n",
    "            ret.append(df['pdr'][i])\n",
    "    #print(ret)\n",
    "    return ret\n",
    "\n",
    " \n",
    "\n",
    "def logistic_regression_init(df):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    target=list()\n",
    "    val_pred=val_prediction_pdr(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "        else:\n",
    "            target.append(1)\n",
    "        \n",
    "        if val_pred[i] < 0.3:\n",
    "            y_pred.append(0)\n",
    "        elif val_pred[i] > 0.75:\n",
    "            y_pred.append(2)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    df['target']=target\n",
    "    df['pred']=y_pred\n",
    "    y=df['pred']\n",
    "    mydata=df.ix[:,(5,7)].values\n",
    "    pdr=df['pdr']\n",
    "    target=df['target']\n",
    "    spearmanr_coefficient,p_value=spearmanr(pdr,target)\n",
    "    #print(' Spearmanr Rank Correlation %0.3f' %(spearmanr_coefficient))\n",
    "    X=scale(mydata)\n",
    "    LogReg=LogisticRegression()\n",
    "    LogReg.fit(X,y)\n",
    "    print (LogReg.score(X,y))\n",
    "    y_pred=LogReg.predict(X)\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y,y_pred))\n",
    "    \n",
    "\n",
    "def arma(df, classes, normalize=False, title=None,cmap=plt.cm.Blues):\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    y_true=list()\n",
    "    y_pred=list()\n",
    "    target=list()\n",
    "    val_pred=val_prediction_pdr(df)\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "        else:\n",
    "            target.append(1)\n",
    "        \n",
    "        if val_pred[i] < 0.3:\n",
    "            y_pred.append(0)\n",
    "        elif val_pred[i] > 0.75:\n",
    "            y_pred.append(2)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    df['target']=target\n",
    "    df['pred']=y_pred\n",
    "    mydata=df.ix[:,(5,7)].values#Column 5 corresponds to the value of PDR and column 7 to the value representing that valu in class(BadnGood and Intermediate)\n",
    "    X=scale(mydata)\n",
    "    y=df['pred']\n",
    "    X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    \n",
    "    my_y=df['target']\n",
    "    arma = ARMA(my_y,order=[4,4])\n",
    "    \n",
    "    res=arma.fit(trend=\"nc\")\n",
    "    params=res.params\n",
    "    residuals = res.resid\n",
    "    p = res.k_ar\n",
    "    q = res.k_ma\n",
    "    k_exog = res.k_exog\n",
    "    k_trend = res.k_trend\n",
    "    steps = 1\n",
    "    \n",
    "    y_pred=arma.predict(params)\n",
    "    \n",
    "    print('y_pred:  ==>', y_pred)\n",
    "    \n",
    "    print ('Accuracy ARMA: ',arma.score(y_pred))\n",
    "    #print (arma.predict(y))\n",
    "    #y_pred=arma.predict(X)\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "def plot_ar4(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(2,1,0))\n",
    "    results_AR=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_AR.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_AR.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\AR.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "        \n",
    "def plot_ma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(0,1,2))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\MA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "    \n",
    "def plot_arima(df):\n",
    "    df=df.set_index('datetime')\n",
    "    ts=df['pdr']\n",
    "    ts_log = np.log(ts)\n",
    "    ts_log_diff = ts_log - ts_log.shift()\n",
    "    model=ARIMA(ts_log,order=(1,0,1))\n",
    "    results_MA=model.fit(disp=-1)\n",
    "    plt.plot(ts_log_diff)\n",
    "    plt.plot(results_MA.fittedvalues,color='red')\n",
    "    plt.title('RSS: %.4f'% sum((results_MA.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\ARIMA.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def plot_arma(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df['pdr']\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    res=model.fit(disp=-1)\n",
    "    plt.plot(ts)\n",
    "    plt.plot(res.fittedvalues,color='red')\n",
    "    #plt.title('RSS: %.4f'% sum((res.fittedvalues-ts_log_diff)**2))\n",
    "    plt.savefig(\"ARMA\\ARMA1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    res= res.predict()\n",
    "\n",
    "    \n",
    "    #plt.ylabel('Baysian Information Criterion')\n",
    "    #plt.plot(res)\n",
    "    #plt.show()\n",
    "    print(\"According to Baysian Information criteria, we can use (ARMA(3,0) model)\")\n",
    "    print (\"min: \",ts.index.min())\n",
    "    print (\"max: \",ts.index.max())\n",
    "    \n",
    "def plot_test(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    df.index = df.index.to_period('H')\n",
    "    #dep = df[[\"channel\",\"pdr\"]].groupby(\"channel\", as_index=True).mean()\n",
    "    nb=df.index.unique()\n",
    "    print(\"Nb de date= \",len(nb))\n",
    "    ts=df['pdr']\n",
    "    print(ts)\n",
    "\n",
    "    \n",
    "def plot_test2(df):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    \n",
    "    ts=df.loc[(df['channel']==11)]\n",
    "    ts=ts['pdr']\n",
    "    print(len(ts))\n",
    "    plt.plot(ts)\n",
    "    results = adfuller(ts.values, autolag='AIC')\n",
    "    print(\"Result[1]===> \",results[1])\n",
    "    if results[1]<=0.05:\n",
    "        print(\"Reject Null hypothesis, the series are stationary\")\n",
    "    else:\n",
    "        print(\"Do not reject Null, the series are not stationary\")\n",
    "    \n",
    "    model=ARMA(ts,order=(1,1))\n",
    "    model_fit=model.fit(disp=0)\n",
    "    print(model_fit.summary())\n",
    "    plt.plot(ts)\n",
    "    pred=model_fit.forecast()\n",
    "    plt.plot(pred[0],color='blue')\n",
    "    plt.title('ARMA(1,1) On channel ',11,' With accuracy: ')\n",
    "    plt.savefig(\"ARMA\\ARMA_Chanel11_1_1.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "\n",
    "def stationarity(ts,seuil):\n",
    "    tsa=np.exp(ts)\n",
    "    rolmean=tsa.rolling(window=1).mean()\n",
    "    rolstd=tsa.rolling(1).std()\n",
    "    \n",
    "    print('rolling_mean: ',rolmean)\n",
    "    #print('rolstd_mean: ',rolstd)\n",
    "    \n",
    "    ts1=ts-rolmean\n",
    "    ts1.dropna(inplace=True)\n",
    "    plt.plot(ts1,color='black')\n",
    "    \n",
    "    ts2=ts-rolstd\n",
    "    ts2.dropna(inplace=True)\n",
    "    plt.plot(ts2,color='yellow')\n",
    "    \n",
    "    plt.plot(ts,color='red')\n",
    "    results = adfuller(ts2, autolag='AIC')\n",
    "    print('ADF Statistic: ', results[0])\n",
    "    print('P-Value: ',results[1])\n",
    "    print('Critical values: ')\n",
    "    for key,value in results[4].items():\n",
    "        print('\\t ',key,': %.3f'%(value))\n",
    "\n",
    "        \n",
    "def channel_in_a_link(df,src,dst):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'],format='%Y-%m-%d %H:%M:%S')\n",
    "    df=df.set_index('datetime')\n",
    "    color_list = [\"blue\", \"red\"]\n",
    "    \n",
    "    \n",
    "    ts=df.loc[(df['src']==src)&((df['dst']==dst))]\n",
    "    #ts=ts.loc[((ts['src']==src)&(ts['dst']==dst))|((ts['src']==dst)&(ts['dst']==src))]\n",
    "    #ts=ts.loc[(ts['src']==src)&(ts['dst']==dst)]\n",
    "    for link, df_link in ts.groupby([\"src\"]):\n",
    "        #dep = df_link[[\"channel\",\"pdr\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #dep = df_link[[\"channel\",\"mean_rssi\"]].groupby(\"datetime\", as_index=True).mean()\n",
    "        #print(dep)\n",
    "        for ln,ln1 in df_link.groupby(\"channel\"):\n",
    "            #print(ln1)\n",
    "            plt.plot(ln1.index, 0.95*ln1.mean_rssi / 100 + ln,\n",
    "            #plt.plot(ln1.index, 0.8 * ln1.pdr + ln,\n",
    "                          '-', zorder=1, markersize=2,\n",
    "                          color=color_list[ln%len(color_list)])\n",
    "        #print(ln1.channel)\n",
    "        day1_start = pd.to_datetime(\"2018-01-11 22:00:00.000\")\n",
    "        day1_stop = pd.to_datetime(\"2018-01-12 06:00:00.000\")\n",
    "        plt.fill_between([day1_start, day1_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        day2_start = pd.to_datetime(\"2018-01-12 22:00:00.000\")\n",
    "        day2_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        plt.fill_between([day2_start, day2_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        #day3_start = pd.to_datetime(\"2018-01-13 20:00:00.000\")\n",
    "        #day3_stop = pd.to_datetime(\"2018-01-13 06:00:00.000\")\n",
    "        #plt.fill_between([day3_start, day3_stop], 0, 30, color='#d5dbdb', alpha=0.5, zorder=1)\n",
    "\n",
    "        plt.xlabel('Time')\n",
    "        #plt.ylabel('PDR (%) per IEEE802.15.4 Channel')\n",
    "        plt.ylabel('Average RSSI (dBm) per IEEE802.15.4 Channel')\n",
    "        plt.ylim([10, 27])\n",
    "        plt.yticks(df.channel.unique())\n",
    "        #plt.xticks(df.index.unique())\n",
    "        plt.grid(True)\n",
    "        #xfmt = md.DateFormatter('%H:%M:%s')\n",
    "        #xfmt = md.DateFormatter('%M:%S')\n",
    "        xfmt = md.DateFormatter('%Y-%m-%d %H')\n",
    "        ax = plt.gca()\n",
    "        ax.xaxis.set_major_formatter(xfmt)\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        #plt.savefig(\"time_pdr\\pdr_time_per_channel_{0}.png\".format(link), format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "\n",
    "def general_channel_in_link(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                channel_in_a_link(df,i,j)\n",
    "        \n",
    "def spaguetti_plot_pdr(df,channel):\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    ts=df['pdr']\n",
    "    #ts=df['mean_rssi']\n",
    "    \n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    ts=df.loc[(df['channel']==channel)]\n",
    "    plt.plot(ts,color='red')\n",
    "    plt.ylim(0, 1)\n",
    "    #plt.ylim(-100, 0)\n",
    "\n",
    "    #plt.xlabel('PDR')\n",
    "    plt.xlabel('Time')\n",
    "    #plt.ylabel('MEAN RSSI')\n",
    "    plt.ylabel('PDR')\n",
    "    plt.title('PDR spaguetti plot by channel')\n",
    "    plt.grid(True)\n",
    "\n",
    "    #plt.show()\n",
    "    title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_spaguethiPlot.png\"\n",
    "    #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_spaguethiPlot.png\"\n",
    "    plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.savefig(\"PDR_BY_RSSI.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "def min_max(df):\n",
    "    mini=list()\n",
    "    maxi=list()\n",
    "    channel_list=df[\"channel\"].unique()\n",
    "    for i in channel_list:\n",
    "        ts=df.loc[(df['channel']==i)]\n",
    "        mini.append(min(ts['pdr'])*1)\n",
    "        maxi.append(max(ts['pdr'])*1)\n",
    "        \n",
    "    print('Mini:===>',mini)\n",
    "    print(\"Maxi:===>\",maxi)\n",
    "    print('channel_List:==>',channel_list)\n",
    "    plt.hist(mini)\n",
    "    #plt.hist([mini, maxi], bins = channel_list, color = ['yellow', 'green'],\n",
    "    #            edgecolor = 'red', hatch = '/', label = ['Mini', 'Maxi'],\n",
    "    #            histtype = 'bar')\n",
    "    plt.ylabel('valeurs')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.title('2 series superposees')\n",
    "    plt.legend()\n",
    "    return channel_list,mini,maxi\n",
    "    \n",
    "\n",
    "    \n",
    "def studies(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "\n",
    "        #rolmean=ts.rolling(500).mean()\n",
    "        rolmean=ts.rolling(window=16).mean()\n",
    "        rolstd=ts.rolling(16).std()\n",
    "        print('Rolmean:====>',rolmean.dropna(inplace=False))\n",
    "        print('Rolstd:====>',rolstd.dropna(inplace=False))\n",
    "        \n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(rolstd.dropna(inplace=False), model='additive', freq=16)\n",
    "        result.plot()\n",
    "        \n",
    "        #2Plot rolling statistics\n",
    "        #orig=plt.plot(ts,color='blue',label='Original')\n",
    "        #print(ts)\n",
    "        mean=plt.plot(rolmean,color='red',label='Rolling Mean')\n",
    "        #std=plt.plot(rolstd,color='black',label='Rolling Std')\n",
    "        plt.legend(loc='best')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #plt.show(block=False)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_TS_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "    \n",
    "def studies_autocorre(df,src,dst):\n",
    "    #df=df.set_index('datetime')\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        for i in range(len(df)):\n",
    "            k=i+1\n",
    "            taille.append(k)\n",
    "        df['taille']=taille\n",
    "        df=df.set_index('taille')\n",
    "\n",
    "        #ts=df['pdr']\n",
    "        ts=df['mean_rssi']\n",
    "        plt.acorr(ts)\n",
    "        plt.legend(loc='best')\n",
    "        plt.xlabel('Lag')\n",
    "\n",
    "        plt.ylabel('Autocorrelation')\n",
    "        #title1='Time Series PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Time Series RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_AUTO_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "def plot_acfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_acf(ts, lags=16)\n",
    "        #title1='Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_ACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        \n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_pacfi(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        plot_pacf(ts, lags=16)\n",
    "        #title1='Partial Autocorrelation PDR '+str(src)+\"==>\"+str(dst)\n",
    "        title1='Partial Autocorrelation  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_PACF_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "def plot_seasonality(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    taille=list()\n",
    "    #print(\"src=\",src,\" dst=\",dst,\" Taille=\",len(df))\n",
    "    if len(df)>0:\n",
    "        #df=df.loc[:,['datetime','pdr']]\n",
    "        df=df.loc[:,['datetime','mean_rssi']]\n",
    "        df=df.set_index('datetime')\n",
    "        ts=df\n",
    "        from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "        result = seasonal_decompose(ts, model='additive', freq=16)\n",
    "        result.plot()\n",
    "        title1='Seasonality PDR '+str(src)+\"==>\"+str(dst)\n",
    "        #title1='Seasonality  RSSI '+str(src)+\"==>\"+str(dst)\n",
    "        plt.title(title1)\n",
    "        \n",
    "        #title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\PDR\\\\PDR_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        title=\"C:\\\\Users\\WSN-LINK\\\\Documents\\\\TEST\\\\SOCALE\\\\CHOOSE\\\\RSSI\\\\RSSI_SEASONALITY_LINK_\"+str(src)+\"===\"+str(dst)+\".png\"\n",
    "        plt.savefig(title, format='png', bbox_inches='tight', pad_inches=0)\n",
    "        plt.clf()\n",
    "        \n",
    "\n",
    "        \n",
    "def general_time_series(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies(df,i,j)\n",
    "                \n",
    "def general_autocorre(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                studies_autocorre(df,i,j)\n",
    "                \n",
    "def general_acf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_acfi(df,i,j)\n",
    "            \n",
    "            \n",
    "def general_pacf(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_pacfi(df,i,j)\n",
    "                \n",
    "def general_seasonality(df):\n",
    "    node_list=df[\"src\"].unique()\n",
    "    for i in node_list:\n",
    "        for j in node_list:\n",
    "            if i!=j:\n",
    "                plot_seasonality(df,i,j)\n",
    "\n",
    "def puissant_arma(df,src,dst):\n",
    "    df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    df=df.set_index('datetime')\n",
    "    df.index=pd.to_datetime(df.index)\n",
    "    print(df)\n",
    "    #ts=df.loc[(df['channel']==11)]\n",
    "    ts=df['pdr']\n",
    "    \n",
    "    print(ts)\n",
    "    size=int(len(ts)*0.66)\n",
    "    train, test=ts[0:size],ts[size:len(ts)]\n",
    "    history=[x for x in train]\n",
    "    predictions=list()\n",
    "    \n",
    "    \n",
    "    for t in range(len(test)):\n",
    "        model=ARMA(history,order=(2,1))\n",
    "        model_fit=model.fit(disp=0)\n",
    "        output=model_fit.forecast()\n",
    "        yhat=output[0]\n",
    "        predictions.append(yhat)\n",
    "        obs=test[t]\n",
    "        history.append(obs)\n",
    "        print('predicted: ', yhat,' and expected= ',obs)\n",
    "    \n",
    "    #r21 = r2_score(test,predictions)\n",
    "    #mse1=mean_squared_error(test,predictions)\n",
    "    #rmse1 = np.sqrt(mse1) \n",
    "   \n",
    "    #print('R-Square is: ',r21,'\\n')\n",
    "    #print('MSE is: ',mse1,'\\n')\n",
    "    #print('RMSE is: ',rmse1) \n",
    "    \n",
    "    #plt.plot(test)\n",
    "    #ts['predictions']=predictions\n",
    "    #plt.plot(ts['predictions'],color='red')\n",
    "    #plt.show()\n",
    "def val_prediction_pdr(df):\n",
    "    ret=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.02:\n",
    "            ret.append(0.5)\n",
    "        elif df['pdr'][i] >= 0.02 and df['pdr'][i] < 0.25:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.25 and df['pdr'][i] < 0.3:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] >= 0.3 and df['pdr'][i] <= 0.35:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.35 and df['pdr'][i] <= 0.73:\n",
    "            ret.append(df['pdr'][i])\n",
    "        elif df['pdr'][i] >= 0.73 and df['pdr'][i] <= 0.75:\n",
    "            ret.append(0.9)\n",
    "        elif df['pdr'][i] > 0.75 and df['pdr'][i] <= 0.8:\n",
    "            ret.append(0.1)\n",
    "        elif df['pdr'][i] > 0.8 and df['pdr'][i] < 0.85:\n",
    "            ret.append(0.5)\n",
    "        else:\n",
    "            ret.append(df['pdr'][i])\n",
    "    return ret\n",
    "\n",
    "def decision_tree_pdr(df,src,dst):\n",
    "    \n",
    "    from sklearn import tree\n",
    "    from sklearn.datasets import load_iris\n",
    "    #iris=load_iris()    \n",
    "    #print(iris)\n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    for i in range(len(df)):\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "            target_names.append('Bad')\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "            target_names.append('Good')\n",
    "        else:\n",
    "            target.append(1)\n",
    "            target_names.append('Intermediate')\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    sample=val_prediction_pdr(df)\n",
    "    df['sample']=sample\n",
    "    #df=df.loc[((df['src']==src)&(df['dst']==dst))]\n",
    "    #print(df['target'].unique())\n",
    "    clf=tree.DecisionTreeClassifier(random_state=0)\n",
    "    colonne=['pdr','mean_rssi','target']\n",
    "    #test=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    test=df[['pdr','mean_rssi']]\n",
    "    clf=clf.fit(test.values,target)\n",
    "    \n",
    "    dot_data=tree.export_graphviz(clf,out_file=None,\n",
    "                                 feature_names=test.columns.values,\n",
    "                                 class_names=df.target_names.unique(),\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "    graph=graphviz.Source(dot_data)\n",
    "    graph.render('link1')\n",
    "    print('Initial: ',test.values)\n",
    "    print('The predicted class is: ',clf.predict(test.values))\n",
    "    print('The decision path is: ',clf.decision_path(test.values))\n",
    "    print('The score is: ',clf.score(test.values,target))\n",
    "    print('The probabilities of each class is: ',clf.predict_proba(test.values))\n",
    "    \n",
    "    #tree.plot_tree(clf.fit(test,df['target']))\n",
    "    \n",
    "    \n",
    "def example(df):\n",
    "    from sklearn import tree\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.tree.export import export_text\n",
    "    iris=load_iris()    \n",
    "    clf=tree.DecisionTreeClassifier()\n",
    "    clf=clf.fit(iris.data,iris.target)\n",
    "    print(\"iris.feature_names==>\", iris.feature_names)\n",
    "    print(\"iris.target_names==>\",iris.target_names)\n",
    "    dot_data=tree.export_graphviz(clf,out_file=None,\n",
    "                                 feature_names=iris.feature_names,\n",
    "                                 class_names=iris.target_names,\n",
    "                                 filled=True, rounded=True,\n",
    "                                 special_characters=True)\n",
    "    graph=graphviz.Source(dot_data)\n",
    "    graph.render('iris')\n",
    "    X=iris['data']\n",
    "    print('X==>',X)\n",
    "    y=iris['target']\n",
    "    print(y)\n",
    "    decision_tree=DecisionTreeClassifier(random_state=0,max_depth=2)\n",
    "    decision_tree=decision_tree.fit(X,y)\n",
    "    #r=export_text(decision_tree,feature_names=iris['feature_names'])\n",
    "    #print(r)\n",
    "def my_split(df,src,dst,size_of_test):\n",
    "    \n",
    "    target=list()\n",
    "    target_names=list()\n",
    "    combine_features=list()\n",
    "    for i in range(len(df)):\n",
    "        combine_features.append(df['pdr']*df['pdr']+df['mean_rssi']*df['mean_rssi'])\n",
    "        if df['pdr'][i] < 0.3:\n",
    "            target.append(0)\n",
    "            target_names.append('Bad')\n",
    "        elif df['pdr'][i] > 0.75:\n",
    "            target.append(2)\n",
    "            target_names.append('Good')\n",
    "        else:\n",
    "            target.append(1)\n",
    "            target_names.append('Intermediate')\n",
    "    df['target']=target\n",
    "    df['target_names']=target_names\n",
    "    df['combined_features']=combined_features\n",
    "    \n",
    "    colonne=['combined_features']\n",
    "    colonne2=['target_names']\n",
    "    ts=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    ts2=df.loc[(df['src']==src)&(df['dst']==dst),colonne2]\n",
    "    \n",
    "    features=ts.values\n",
    "    labels=ts2.values;\n",
    "    print(features)\n",
    "    print(labels)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    colonne=['pdr','mean_rssi','target']\n",
    "    #test=df.loc[(df['src']==src)&(df['dst']==dst),colonne]\n",
    "    test=df[['pdr','mean_rssi']]\n",
    "    \n",
    "\n",
    "    \n",
    "my_split(df,6,33,0.25)\n",
    "#tree.plot_tree(clf.fit(test,df['target']))\n",
    "#printer(df)    \n",
    "#example(df)    \n",
    "#decision_tree_pdr(df,0,20)   \n",
    "#plot_particular_seasonality(df,4,32,13)\n",
    "#general_seasonality(df)                \n",
    "#plot_seasonality(df,4,32)\n",
    "#test=df=df.loc[((df['src']==0)&(df['dst']==12))]              \n",
    "#print(test)\n",
    "#general_pacf(df)\n",
    "#general_acf(df)\n",
    "#studies(df,4,32)\n",
    "#plot_acfi(df,4,32)\n",
    "#plot_pacfi(df,4,32)\n",
    "#general_autocorre(df)\n",
    "#studies_autocorre(df,4,32)   \n",
    "#general_time_series(df)\n",
    "#min_max(df)\n",
    "#spaguetti_plot_pdr(df,11)    \n",
    "#channel_in_a_link(df,4,32)    \n",
    "#general_channel_in_link(df)\n",
    "#channel_in_a_link(df,1,14)\n",
    "#print(df)\n",
    "#puissant_arma(df,4,32)    \n",
    "#plot_test(df)    \n",
    "#plot_test2(df)    \n",
    "#plot_arma(df)\n",
    "#plot_ar4(df)\n",
    "#plot_ma(df)\n",
    "#plot_arima(df)   \n",
    "    #np.set_printoptions(precision=2)\n",
    "    \n",
    "#logistic_regression(df)\n",
    "#arma(df, classes=class_names, normalize=True,title='RF Accuracy of PDR without resampling= ')\n",
    "#plt.savefig(\"RF_CM_WithoutReampling.png\", format='png', bbox_inches='tight', pad_inches=0)\n",
    "#linear_SVM(df, classes=class_names, normalize=True,title='SVM Accuracy of PDR= ') \n",
    "#plt.savefig(\"SVMConfusionMatrixWithoutNormalization.png\", format='png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
